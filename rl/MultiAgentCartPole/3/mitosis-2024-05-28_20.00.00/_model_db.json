{"_default": {"1": {"model_id": "2024-05-28_20.40.35~EGHSbo", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.40.35~EGHSbo--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.40.35~EGHSbo", "parent_policy_id": null, "score": 0.3393981432167884, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 20:53:18.422906"}, "2": {"model_id": "2024-05-28_20.40.50~N8trZR", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.40.50~N8trZR--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.40.50~N8trZR", "parent_policy_id": null, "score": 0.3116333443308376, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 20:53:57.997437"}, "3": {"model_id": "2024-05-28_20.41.05~BBv516", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.41.05~BBv516--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.41.05~BBv516", "parent_policy_id": null, "score": 0.3537372131693809, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 20:54:10.718315"}, "4": {"model_id": "2024-05-28_20.53.18~GLWl38", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.53.18~GLWl38--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.53.18~GLWl38", "parent_policy_id": null, "score": 0.38559986615842806, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:06:38.220796"}, "5": {"model_id": "2024-05-28_20.53.58~y9xmO4", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.53.58~y9xmO4--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.53.58~y9xmO4", "parent_policy_id": null, "score": 0.30950010960669627, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:07:18.352792"}, "6": {"model_id": "2024-05-28_20.54.10~6I7W4P", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_20.54.10~6I7W4P--state_dict.pth", "model_info": {"policy_id": "2024-05-28_20.54.10~6I7W4P", "parent_policy_id": null, "score": 0.38708981371983203, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:07:18.500144"}, "7": {"model_id": "2024-05-28_21.06.38~v0m9db", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.06.38~v0m9db--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.06.38~v0m9db", "parent_policy_id": null, "score": 0.34620673187122625, "steps_trained": 50000, "env_steps_trained": 1600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:20:00.016807"}, "8": {"model_id": "2024-05-28_21.07.18~YJS6T6", "parent_model_id": "2024-05-28_20.40.50~N8trZR", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.07.18~YJS6T6--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.07.18~YJS6T6", "parent_policy_id": "2024-05-28_20.40.50~N8trZR", "score": 0.5965361072983597, "steps_trained": 100000, "env_steps_trained": 3200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:20:40.375514"}, "9": {"model_id": "2024-05-28_21.07.18~Vs4JWw", "parent_model_id": "2024-05-28_20.54.10~6I7W4P", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.07.18~Vs4JWw--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.07.18~Vs4JWw", "parent_policy_id": "2024-05-28_20.54.10~6I7W4P", "score": 0.891030241951452, "steps_trained": 100000, "env_steps_trained": 3200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:20:40.495542"}, "10": {"model_id": "2024-05-28_21.20.00~cuZISG", "parent_model_id": "2024-05-28_20.40.35~EGHSbo", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.20.00~cuZISG--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.20.00~cuZISG", "parent_policy_id": "2024-05-28_20.40.35~EGHSbo", "score": 1.197004404071376, "steps_trained": 100000, "env_steps_trained": 3200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:33:12.437345"}, "11": {"model_id": "2024-05-28_21.20.40~asJ3it", "parent_model_id": "2024-05-28_20.54.10~6I7W4P", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.20.40~asJ3it--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.20.40~asJ3it", "parent_policy_id": "2024-05-28_20.54.10~6I7W4P", "score": 0.8803467077904727, "steps_trained": 100000, "env_steps_trained": 3200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:33:55.216308"}, "12": {"model_id": "2024-05-28_21.20.40~4qsqZ9", "parent_model_id": "2024-05-28_21.07.18~Vs4JWw", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.20.40~4qsqZ9--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.20.40~4qsqZ9", "parent_policy_id": "2024-05-28_21.07.18~Vs4JWw", "score": 2.376392715043216, "steps_trained": 150000, "env_steps_trained": 4800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:33:55.344337"}, "13": {"model_id": "2024-05-28_21.33.12~rST4Pk", "parent_model_id": "2024-05-28_21.20.00~cuZISG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.33.12~rST4Pk--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.33.12~rST4Pk", "parent_policy_id": "2024-05-28_21.20.00~cuZISG", "score": 2.761476819125562, "steps_trained": 150000, "env_steps_trained": 4800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:46:08.372844"}, "14": {"model_id": "2024-05-28_21.33.55~6uzn1n", "parent_model_id": "2024-05-28_21.20.40~4qsqZ9", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.33.55~6uzn1n--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.33.55~6uzn1n", "parent_policy_id": "2024-05-28_21.20.40~4qsqZ9", "score": 6.367667679180558, "steps_trained": 200000, "env_steps_trained": 6400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:47:07.131553"}, "15": {"model_id": "2024-05-28_21.33.55~0WSNco", "parent_model_id": "2024-05-28_21.20.00~cuZISG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_21.33.55~0WSNco--state_dict.pth", "model_info": {"policy_id": "2024-05-28_21.33.55~0WSNco", "parent_policy_id": "2024-05-28_21.20.00~cuZISG", "score": 2.8333407460822126, "steps_trained": 150000, "env_steps_trained": 4800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 21:47:07.302663"}, "16": {"model_id": "2024-05-28_22.03.48~XPPD7g", "parent_model_id": "2024-05-28_21.33.12~rST4Pk", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.03.48~XPPD7g--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.03.48~XPPD7g", "parent_policy_id": "2024-05-28_21.33.12~rST4Pk", "score": 3.9889727228474565, "steps_trained": 200000, "env_steps_trained": 5600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:11:49.488220"}, "17": {"model_id": "2024-05-28_22.04.03~BSz2Jz", "parent_model_id": "2024-05-28_21.33.55~6uzn1n", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.04.03~BSz2Jz--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.04.03~BSz2Jz", "parent_policy_id": "2024-05-28_21.33.55~6uzn1n", "score": 9.46667998019024, "steps_trained": 250000, "env_steps_trained": 7200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:12:13.569634"}, "18": {"model_id": "2024-05-28_22.04.18~j8Jw25", "parent_model_id": "2024-05-28_21.33.55~6uzn1n", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.04.18~j8Jw25--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.04.18~j8Jw25", "parent_policy_id": "2024-05-28_21.33.55~6uzn1n", "score": 10.15557941974592, "steps_trained": 250000, "env_steps_trained": 7200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:12:38.494671"}, "19": {"model_id": "2024-05-28_22.11.49~9pmZUv", "parent_model_id": "2024-05-28_21.33.55~6uzn1n", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.11.49~9pmZUv--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.11.49~9pmZUv", "parent_policy_id": "2024-05-28_21.33.55~6uzn1n", "score": 8.02483344284235, "steps_trained": 250000, "env_steps_trained": 7200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:20:06.920779"}, "20": {"model_id": "2024-05-28_22.12.13~Xmz6UN", "parent_model_id": "2024-05-28_22.04.03~BSz2Jz", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.12.13~Xmz6UN--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.12.13~Xmz6UN", "parent_policy_id": "2024-05-28_22.04.03~BSz2Jz", "score": 17.06428090321323, "steps_trained": 300000, "env_steps_trained": 8000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:20:27.913232"}, "21": {"model_id": "2024-05-28_22.12.38~Jj57EC", "parent_model_id": "2024-05-28_22.04.03~BSz2Jz", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.12.38~Jj57EC--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.12.38~Jj57EC", "parent_policy_id": "2024-05-28_22.04.03~BSz2Jz", "score": 9.79321149001462, "steps_trained": 300000, "env_steps_trained": 8000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:20:56.456333"}, "22": {"model_id": "2024-05-28_22.20.07~FmOrA1", "parent_model_id": "2024-05-28_22.11.49~9pmZUv", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.20.07~FmOrA1--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.20.07~FmOrA1", "parent_policy_id": "2024-05-28_22.11.49~9pmZUv", "score": 9.136594573582881, "steps_trained": 300000, "env_steps_trained": 8000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:28:22.444060"}, "23": {"model_id": "2024-05-28_22.20.28~SsufR9", "parent_model_id": "2024-05-28_22.12.13~Xmz6UN", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.20.28~SsufR9--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.20.28~SsufR9", "parent_policy_id": "2024-05-28_22.12.13~Xmz6UN", "score": 16.12980291918775, "steps_trained": 350000, "env_steps_trained": 8800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:28:41.152243"}, "24": {"model_id": "2024-05-28_22.20.56~JOCugl", "parent_model_id": "2024-05-28_22.12.13~Xmz6UN", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.20.56~JOCugl--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.20.56~JOCugl", "parent_policy_id": "2024-05-28_22.12.13~Xmz6UN", "score": 13.476240722036373, "steps_trained": 350000, "env_steps_trained": 8800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:29:12.317057"}, "25": {"model_id": "2024-05-28_22.28.22~qszXJA", "parent_model_id": "2024-05-28_22.12.13~Xmz6UN", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.28.22~qszXJA--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.28.22~qszXJA", "parent_policy_id": "2024-05-28_22.12.13~Xmz6UN", "score": 17.97384283201664, "steps_trained": 350000, "env_steps_trained": 8800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:36:34.743646"}, "26": {"model_id": "2024-05-28_22.28.41~PSkKj8", "parent_model_id": "2024-05-28_22.20.28~SsufR9", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.28.41~PSkKj8--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.28.41~PSkKj8", "parent_policy_id": "2024-05-28_22.20.28~SsufR9", "score": 25.728656508285447, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:36:52.771131"}, "27": {"model_id": "2024-05-28_22.29.12~wJcdJe", "parent_model_id": "2024-05-28_22.12.38~Jj57EC", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.29.12~wJcdJe--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.29.12~wJcdJe", "parent_policy_id": "2024-05-28_22.12.38~Jj57EC", "score": 23.497913386476647, "steps_trained": 350000, "env_steps_trained": 8800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:37:25.193965"}, "28": {"model_id": "2024-05-28_22.36.34~had5vp", "parent_model_id": "2024-05-28_22.04.03~BSz2Jz", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.36.34~had5vp--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.36.34~had5vp", "parent_policy_id": "2024-05-28_22.04.03~BSz2Jz", "score": 16.576526164578972, "steps_trained": 300000, "env_steps_trained": 8000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:44:47.559337"}, "29": {"model_id": "2024-05-28_22.36.53~VmRNfG", "parent_model_id": "2024-05-28_22.28.41~PSkKj8", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.36.53~VmRNfG--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.36.53~VmRNfG", "parent_policy_id": "2024-05-28_22.28.41~PSkKj8", "score": 25.28824776296902, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:45:04.384962"}, "30": {"model_id": "2024-05-28_22.37.25~3b05TO", "parent_model_id": "2024-05-28_22.29.12~wJcdJe", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.37.25~3b05TO--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.37.25~3b05TO", "parent_policy_id": "2024-05-28_22.29.12~wJcdJe", "score": 15.059011592608536, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:45:38.068836"}, "31": {"model_id": "2024-05-28_22.44.47~SWBrcf", "parent_model_id": "2024-05-28_22.28.22~qszXJA", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.44.47~SWBrcf--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.44.47~SWBrcf", "parent_policy_id": "2024-05-28_22.28.22~qszXJA", "score": 26.846303270436795, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:52:56.124337"}, "32": {"model_id": "2024-05-28_22.45.04~Zh7iTt", "parent_model_id": "2024-05-28_22.28.41~PSkKj8", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.45.04~Zh7iTt--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.45.04~Zh7iTt", "parent_policy_id": "2024-05-28_22.28.41~PSkKj8", "score": 19.132930222835384, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:53:09.945860"}, "33": {"model_id": "2024-05-28_22.45.38~bMEaRM", "parent_model_id": "2024-05-28_22.28.41~PSkKj8", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.45.38~bMEaRM--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.45.38~bMEaRM", "parent_policy_id": "2024-05-28_22.28.41~PSkKj8", "score": 16.208587789932317, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 22:53:46.429375"}, "34": {"model_id": "2024-05-28_22.52.56~UkPQsu", "parent_model_id": "2024-05-28_22.28.22~qszXJA", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.52.56~UkPQsu--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.52.56~UkPQsu", "parent_policy_id": "2024-05-28_22.28.22~qszXJA", "score": 16.73928338700924, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:01:09.568270"}, "35": {"model_id": "2024-05-28_22.53.10~NxiZmB", "parent_model_id": "2024-05-28_22.44.47~SWBrcf", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.53.10~NxiZmB--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.53.10~NxiZmB", "parent_policy_id": "2024-05-28_22.44.47~SWBrcf", "score": 26.623912180458575, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:01:21.116379"}, "36": {"model_id": "2024-05-28_22.53.46~UtNJV6", "parent_model_id": "2024-05-28_22.36.53~VmRNfG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_22.53.46~UtNJV6--state_dict.pth", "model_info": {"policy_id": "2024-05-28_22.53.46~UtNJV6", "parent_policy_id": "2024-05-28_22.36.53~VmRNfG", "score": 20.19502348551073, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:01:59.533783"}, "37": {"model_id": "2024-05-28_23.01.09~7ZvbTm", "parent_model_id": "2024-05-28_22.20.28~SsufR9", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.01.09~7ZvbTm--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.01.09~7ZvbTm", "parent_policy_id": "2024-05-28_22.20.28~SsufR9", "score": 14.598822190187542, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:09:23.185896"}, "38": {"model_id": "2024-05-28_23.01.21~DYpgo1", "parent_model_id": "2024-05-28_22.44.47~SWBrcf", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.01.21~DYpgo1--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.01.21~DYpgo1", "parent_policy_id": "2024-05-28_22.44.47~SWBrcf", "score": 22.308045015705837, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:09:31.272570"}, "39": {"model_id": "2024-05-28_23.01.59~ZOgs3C", "parent_model_id": "2024-05-28_22.53.46~UtNJV6", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.01.59~ZOgs3C--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.01.59~ZOgs3C", "parent_policy_id": "2024-05-28_22.53.46~UtNJV6", "score": 23.7987962708755, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:10:15.300152"}, "40": {"model_id": "2024-05-28_23.09.23~gv5cdh", "parent_model_id": "2024-05-28_22.36.53~VmRNfG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.09.23~gv5cdh--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.09.23~gv5cdh", "parent_policy_id": "2024-05-28_22.36.53~VmRNfG", "score": 25.310329874150938, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:17:27.915281"}, "41": {"model_id": "2024-05-28_23.09.31~jf6H1y", "parent_model_id": "2024-05-28_22.37.25~3b05TO", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.09.31~jf6H1y--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.09.31~jf6H1y", "parent_policy_id": "2024-05-28_22.37.25~3b05TO", "score": 22.60774395948615, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:17:43.966980"}, "42": {"model_id": "2024-05-28_23.10.15~6QVFyI", "parent_model_id": "2024-05-28_22.36.53~VmRNfG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.10.15~6QVFyI--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.10.15~6QVFyI", "parent_policy_id": "2024-05-28_22.36.53~VmRNfG", "score": 27.562747808008318, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:18:28.124912"}, "43": {"model_id": "2024-05-28_23.17.28~tKHbuA", "parent_model_id": "2024-05-28_22.44.47~SWBrcf", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.17.28~tKHbuA--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.17.28~tKHbuA", "parent_policy_id": "2024-05-28_22.44.47~SWBrcf", "score": 25.872602337267452, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:25:31.161782"}, "44": {"model_id": "2024-05-28_23.17.44~QlbUFa", "parent_model_id": "2024-05-28_22.28.22~qszXJA", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.17.44~QlbUFa--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.17.44~QlbUFa", "parent_policy_id": "2024-05-28_22.28.22~qszXJA", "score": 33.90417024646837, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:25:50.168362"}, "45": {"model_id": "2024-05-28_23.18.28~rlRteB", "parent_model_id": "2024-05-28_23.09.23~gv5cdh", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.18.28~rlRteB--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.18.28~rlRteB", "parent_policy_id": "2024-05-28_23.09.23~gv5cdh", "score": 34.19302204001851, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:26:37.067425"}, "46": {"model_id": "2024-05-28_23.25.31~3Qf6TW", "parent_model_id": "2024-05-28_23.17.28~tKHbuA", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.25.31~3Qf6TW--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.25.31~3Qf6TW", "parent_policy_id": "2024-05-28_23.17.28~tKHbuA", "score": 13.4623064487865, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:33:35.156465"}, "47": {"model_id": "2024-05-28_23.25.50~AZeaFt", "parent_model_id": "2024-05-28_22.36.53~VmRNfG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.25.50~AZeaFt--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.25.50~AZeaFt", "parent_policy_id": "2024-05-28_22.36.53~VmRNfG", "score": 35.60724578418207, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:33:57.095220"}, "48": {"model_id": "2024-05-28_23.26.37~EUawd0", "parent_model_id": "2024-05-28_23.17.28~tKHbuA", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.26.37~EUawd0--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.26.37~EUawd0", "parent_policy_id": "2024-05-28_23.17.28~tKHbuA", "score": 12.901167594545782, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:34:42.014602"}, "49": {"model_id": "2024-05-28_23.33.35~CUWu2J", "parent_model_id": "2024-05-28_23.18.28~rlRteB", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.33.35~CUWu2J--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.33.35~CUWu2J", "parent_policy_id": "2024-05-28_23.18.28~rlRteB", "score": 35.249084915019885, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:41:43.532337"}, "50": {"model_id": "2024-05-28_23.33.57~BuFN2D", "parent_model_id": "2024-05-28_23.17.44~QlbUFa", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.33.57~BuFN2D--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.33.57~BuFN2D", "parent_policy_id": "2024-05-28_23.17.44~QlbUFa", "score": 25.908723841211227, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:42:08.830102"}, "51": {"model_id": "2024-05-28_23.34.42~uId3Dg", "parent_model_id": "2024-05-28_23.25.50~AZeaFt", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.34.42~uId3Dg--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.34.42~uId3Dg", "parent_policy_id": "2024-05-28_23.25.50~AZeaFt", "score": 24.827777822622412, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:42:48.274794"}, "52": {"model_id": "2024-05-28_23.41.43~p5yas3", "parent_model_id": "2024-05-28_23.17.44~QlbUFa", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.41.43~p5yas3--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.41.43~p5yas3", "parent_policy_id": "2024-05-28_23.17.44~QlbUFa", "score": NaN, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-28 23:49:46.971494"}, "53": {"model_id": "2024-05-29_01.22.17~mi8ahU", "parent_model_id": "2024-05-28_23.25.50~AZeaFt", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/3/mitosis-2024-05-28_20.00.00\\2024-05-29_01.22.17~mi8ahU--state_dict.pth", "model_info": {"policy_id": "2024-05-29_01.22.17~mi8ahU", "parent_policy_id": "2024-05-28_23.25.50~AZeaFt", "score": 8.272237168167011, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-29 01:31:14.944489"}, "54": {"model_id": "2024-05-29_01.22.32~xEO93C", "parent_model_id": "2024-05-28_23.18.28~rlRteB", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/3/mitosis-2024-05-28_20.00.00\\2024-05-29_01.22.32~xEO93C--state_dict.pth", "model_info": {"policy_id": "2024-05-29_01.22.32~xEO93C", "parent_policy_id": "2024-05-28_23.18.28~rlRteB", "score": 17.41539176124617, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-29 01:31:32.733210"}, "55": {"model_id": "2024-05-29_01.22.48~aqRz9m", "parent_model_id": "2024-05-28_22.36.53~VmRNfG", "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/3/mitosis-2024-05-28_20.00.00\\2024-05-29_01.22.48~aqRz9m--state_dict.pth", "model_info": {"policy_id": "2024-05-29_01.22.48~aqRz9m", "parent_policy_id": "2024-05-28_22.36.53~VmRNfG", "score": 21.509429291436966, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-29 01:31:48.107299"}}}
{"_default": {"42": {"model_id": "2024-05-28_23.10.15~6QVFyI", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.10.15~6QVFyI--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.10.15~6QVFyI", "parent_policy_id": null, "score": 0.02756274780800832, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:18:28.124912"}, "44": {"model_id": "2024-05-28_23.17.44~QlbUFa", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.17.44~QlbUFa--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.17.44~QlbUFa", "parent_policy_id": null, "score": 0.03390417024646837, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:25:50.168362"}, "45": {"model_id": "2024-05-28_23.18.28~rlRteB", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.18.28~rlRteB--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.18.28~rlRteB", "parent_policy_id": null, "score": 0.03419302204001851, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:26:37.067425"}, "47": {"model_id": "2024-05-28_23.25.50~AZeaFt", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.25.50~AZeaFt--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.25.50~AZeaFt", "parent_policy_id": null, "score": 0.03560724578418207, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:33:57.095220"}, "49": {"model_id": "2024-05-28_23.33.35~CUWu2J", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.33.35~CUWu2J--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.33.35~CUWu2J", "parent_policy_id": null, "score": 0.035249084915019886, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:41:43.532337"}, "52": {"model_id": "2024-05-28_23.41.43~p5yas3", "parent_model_id": null, "state_dict_path": "E:/saved_models/rl/MultiAgentCartPole/2/mitosis-2024-05-28_20.00.00\\2024-05-28_23.41.43~p5yas3--state_dict.pth", "model_info": {"policy_id": "2024-05-28_23.41.43~p5yas3", "parent_policy_id": null, "score": 0.03, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-28 23:49:46.971494"}, "53": {"model_id": "2024-05-29_16.46.30~2Tzt96", "parent_model_id": "2024-05-28_23.25.50~AZeaFt", "model_info": {"policy_id": "2024-05-29_16.46.30~2Tzt96", "parent_policy_id": "2024-05-28_23.25.50~AZeaFt", "score": 1.97607864978117, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 16:55:39.722024"}, "54": {"model_id": "2024-05-29_16.46.45~xVkzEE", "parent_model_id": "2024-05-28_23.25.50~AZeaFt", "model_info": {"policy_id": "2024-05-29_16.46.45~xVkzEE", "parent_policy_id": "2024-05-28_23.25.50~AZeaFt", "score": 1.9846292471369842, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 16:56:03.581984"}, "55": {"model_id": "2024-05-29_16.47.00~kQ76m5", "parent_model_id": "2024-05-28_23.10.15~6QVFyI", "model_info": {"policy_id": "2024-05-29_16.47.00~kQ76m5", "parent_policy_id": "2024-05-28_23.10.15~6QVFyI", "score": 1.799759734225376, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 16:56:36.729161"}, "56": {"model_id": "2024-05-29_16.55.39~v4NuI2", "parent_model_id": "2024-05-29_16.46.30~2Tzt96", "model_info": {"policy_id": "2024-05-29_16.55.39~v4NuI2", "parent_policy_id": "2024-05-29_16.46.30~2Tzt96", "score": 2.2263968756465387, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:05:19.642716"}, "57": {"model_id": "2024-05-29_16.56.03~kmTuGa", "parent_model_id": "2024-05-29_16.46.30~2Tzt96", "model_info": {"policy_id": "2024-05-29_16.56.03~kmTuGa", "parent_policy_id": "2024-05-29_16.46.30~2Tzt96", "score": 3.312568493699882, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:05:37.637066"}, "58": {"model_id": "2024-05-29_16.56.36~gEFwSY", "parent_model_id": "2024-05-29_16.46.45~xVkzEE", "model_info": {"policy_id": "2024-05-29_16.56.36~gEFwSY", "parent_policy_id": "2024-05-29_16.46.45~xVkzEE", "score": 2.8889820386242135, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:06:16.550950"}, "59": {"model_id": "2024-05-29_17.05.19~boQ4YN", "parent_model_id": "2024-05-29_16.55.39~v4NuI2", "model_info": {"policy_id": "2024-05-29_17.05.19~boQ4YN", "parent_policy_id": "2024-05-29_16.55.39~v4NuI2", "score": 2.743066238417105, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:14:44.773135"}, "60": {"model_id": "2024-05-29_17.05.37~nRK7nR", "parent_model_id": "2024-05-29_16.56.03~kmTuGa", "model_info": {"policy_id": "2024-05-29_17.05.37~nRK7nR", "parent_policy_id": "2024-05-29_16.56.03~kmTuGa", "score": 4.981492179152891, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:14:58.639507"}, "61": {"model_id": "2024-05-29_17.06.16~Fij6Ld", "parent_model_id": "2024-05-29_16.56.03~kmTuGa", "model_info": {"policy_id": "2024-05-29_17.06.16~Fij6Ld", "parent_policy_id": "2024-05-29_16.56.03~kmTuGa", "score": 3.5214983581073263, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-05-29 17:15:39.774191"}, "62": {"model_id": "2024-05-31_16.41.15~AiLNdo", "parent_model_id": "2024-05-29_17.05.37~nRK7nR", "model_info": {"policy_id": "2024-05-31_16.41.15~AiLNdo", "parent_policy_id": "2024-05-29_17.05.37~nRK7nR", "score": 6.353063333474265, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-05-31 16:50:26.539705"}, "63": {"model_id": "2024-05-31_16.41.30~UW854S", "parent_model_id": "2024-05-29_17.05.19~boQ4YN", "model_info": {"policy_id": "2024-05-31_16.41.30~UW854S", "parent_policy_id": "2024-05-29_17.05.19~boQ4YN", "score": 3.238182119852998, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-05-31 16:50:46.782453"}, "64": {"model_id": "2024-05-31_16.41.45~QML4so", "parent_model_id": "2024-05-28_23.17.44~QlbUFa", "model_info": {"policy_id": "2024-05-31_16.41.45~QML4so", "parent_policy_id": "2024-05-28_23.17.44~QlbUFa", "score": 2.193797955171222, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-05-31 16:51:22.610001"}, "65": {"model_id": "2024-05-31_16.50.26~onDlZJ", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_16.50.26~onDlZJ", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 5.1323528570120205, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 16:59:38.660109"}, "66": {"model_id": "2024-05-31_16.50.46~rUvU3f", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_16.50.46~rUvU3f", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 5.6792865414115195, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:00:05.820646"}, "67": {"model_id": "2024-05-31_16.51.22~3OwcrC", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_16.51.22~3OwcrC", "parent_policy_id": null, "score": 0.24223794885323263, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 17:01:04.758675"}, "68": {"model_id": "2024-05-31_16.59.38~xtkhdQ", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_16.59.38~xtkhdQ", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 5.753752112637404, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:08:57.631263"}, "69": {"model_id": "2024-05-31_17.00.05~Z0hxkH", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_17.00.05~Z0hxkH", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 4.642197102869679, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:09:26.039522"}, "70": {"model_id": "2024-05-31_17.01.05~Jb68Jc", "parent_model_id": "2024-05-31_16.50.26~onDlZJ", "model_info": {"policy_id": "2024-05-31_17.01.05~Jb68Jc", "parent_policy_id": "2024-05-31_16.50.26~onDlZJ", "score": 4.797011875413597, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:10:24.170929"}, "71": {"model_id": "2024-05-31_17.08.57~TK9Ngd", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_17.08.57~TK9Ngd", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 5.468371518155205, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:18:08.989124"}, "72": {"model_id": "2024-05-31_17.09.26~sOliBy", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_17.09.26~sOliBy", "parent_policy_id": null, "score": 0.2506651091069484, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 17:18:57.874800"}, "73": {"model_id": "2024-05-31_17.10.24~YPlk6E", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_17.10.24~YPlk6E", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 4.530882111089833, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:19:28.982369"}, "74": {"model_id": "2024-05-31_17.18.09~VuwkEc", "parent_model_id": "2024-05-31_17.08.57~TK9Ngd", "model_info": {"policy_id": "2024-05-31_17.18.09~VuwkEc", "parent_policy_id": "2024-05-31_17.08.57~TK9Ngd", "score": 4.822652856406229, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:27:14.103246"}, "75": {"model_id": "2024-05-31_17.18.57~jwoEjV", "parent_model_id": "2024-05-31_17.08.57~TK9Ngd", "model_info": {"policy_id": "2024-05-31_17.18.57~jwoEjV", "parent_policy_id": "2024-05-31_17.08.57~TK9Ngd", "score": 3.7367842491160195, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:28:09.476249"}, "76": {"model_id": "2024-05-31_17.19.29~zsiX5i", "parent_model_id": "2024-05-31_16.41.15~AiLNdo", "model_info": {"policy_id": "2024-05-31_17.19.29~zsiX5i", "parent_policy_id": "2024-05-31_16.41.15~AiLNdo", "score": 7.252170334698026, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-05-31 17:28:27.664727"}, "77": {"model_id": "2024-05-31_17.27.14~rsObi8", "parent_model_id": "2024-05-31_17.00.05~Z0hxkH", "model_info": {"policy_id": "2024-05-31_17.27.14~rsObi8", "parent_policy_id": "2024-05-31_17.00.05~Z0hxkH", "score": 5.040859590299304, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:36:31.193974"}, "78": {"model_id": "2024-05-31_17.28.09~Soboqy", "parent_model_id": "2024-05-31_16.50.46~rUvU3f", "model_info": {"policy_id": "2024-05-31_17.28.09~Soboqy", "parent_policy_id": "2024-05-31_16.50.46~rUvU3f", "score": 5.941427895901782, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:37:24.582740"}, "79": {"model_id": "2024-05-31_17.28.27~YQr4Hn", "parent_model_id": "2024-05-31_17.08.57~TK9Ngd", "model_info": {"policy_id": "2024-05-31_17.28.27~YQr4Hn", "parent_policy_id": "2024-05-31_17.08.57~TK9Ngd", "score": 6.733849922807403, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:37:30.445161"}, "80": {"model_id": "2024-05-31_17.36.31~nPmTqB", "parent_model_id": "2024-05-31_17.08.57~TK9Ngd", "model_info": {"policy_id": "2024-05-31_17.36.31~nPmTqB", "parent_policy_id": "2024-05-31_17.08.57~TK9Ngd", "score": 6.531573519390431, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 17:45:47.454676"}, "81": {"model_id": "2024-05-31_17.37.30~YfHOb9", "parent_model_id": "2024-05-31_17.28.27~YQr4Hn", "model_info": {"policy_id": "2024-05-31_17.37.30~YfHOb9", "parent_policy_id": "2024-05-31_17.28.27~YQr4Hn", "score": 6.933888063064389, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 17:46:20.908129"}, "82": {"model_id": "2024-05-31_17.37.24~vtQxBc", "parent_model_id": "2024-05-31_17.18.09~VuwkEc", "model_info": {"policy_id": "2024-05-31_17.37.24~vtQxBc", "parent_policy_id": "2024-05-31_17.18.09~VuwkEc", "score": 6.051837279488055, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 17:46:39.331658"}, "83": {"model_id": "2024-05-31_17.45.47~Wiz72L", "parent_model_id": "2024-05-31_17.28.27~YQr4Hn", "model_info": {"policy_id": "2024-05-31_17.45.47~Wiz72L", "parent_policy_id": "2024-05-31_17.28.27~YQr4Hn", "score": 4.402427273224242, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 17:54:58.198527"}, "84": {"model_id": "2024-05-31_17.46.20~9v0txI", "parent_model_id": "2024-05-31_17.28.09~Soboqy", "model_info": {"policy_id": "2024-05-31_17.46.20~9v0txI", "parent_policy_id": "2024-05-31_17.28.09~Soboqy", "score": 4.417021419332282, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 17:55:26.952504"}, "85": {"model_id": "2024-05-31_17.46.39~aZWd9r", "parent_model_id": "2024-05-31_17.36.31~nPmTqB", "model_info": {"policy_id": "2024-05-31_17.46.39~aZWd9r", "parent_policy_id": "2024-05-31_17.36.31~nPmTqB", "score": 6.430235729282651, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 17:55:45.588453"}, "86": {"model_id": "2024-05-31_17.54.58~7egT4M", "parent_model_id": "2024-05-31_17.37.30~YfHOb9", "model_info": {"policy_id": "2024-05-31_17.54.58~7egT4M", "parent_policy_id": "2024-05-31_17.37.30~YfHOb9", "score": 4.226296422483304, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-05-31 18:04:05.342328"}, "87": {"model_id": "2024-05-31_17.55.27~aQwARz", "parent_model_id": "2024-05-31_17.36.31~nPmTqB", "model_info": {"policy_id": "2024-05-31_17.55.27~aQwARz", "parent_policy_id": "2024-05-31_17.36.31~nPmTqB", "score": 8.090123615107398, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 18:04:31.280139"}, "88": {"model_id": "2024-05-31_17.55.45~3DEWft", "parent_model_id": "2024-05-31_17.28.09~Soboqy", "model_info": {"policy_id": "2024-05-31_17.55.45~3DEWft", "parent_policy_id": "2024-05-31_17.28.09~Soboqy", "score": 5.453634755820442, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 18:04:51.465859"}, "89": {"model_id": "2024-05-31_18.04.05~2YVOhS", "parent_model_id": "2024-05-31_17.19.29~zsiX5i", "model_info": {"policy_id": "2024-05-31_18.04.05~2YVOhS", "parent_policy_id": "2024-05-31_17.19.29~zsiX5i", "score": 4.269839739409457, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-05-31 18:13:16.479316"}, "90": {"model_id": "2024-05-31_18.04.31~Dwytzn", "parent_model_id": "2024-05-31_17.28.27~YQr4Hn", "model_info": {"policy_id": "2024-05-31_18.04.31~Dwytzn", "parent_policy_id": "2024-05-31_17.28.27~YQr4Hn", "score": 6.988797626465182, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 18:13:41.863343"}, "91": {"model_id": "2024-05-31_18.04.51~g5AFrn", "parent_model_id": "2024-05-31_17.36.31~nPmTqB", "model_info": {"policy_id": "2024-05-31_18.04.51~g5AFrn", "parent_policy_id": "2024-05-31_17.36.31~nPmTqB", "score": 5.311991010265514, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-05-31 18:14:02.634753"}, "92": {"model_id": "2024-05-31_18.18.34~HHS18S", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_18.18.34~HHS18S", "parent_policy_id": null, "score": 0.24865721793804765, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 18:27:52.753994"}, "93": {"model_id": "2024-05-31_18.18.49~J7G5Wl", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_18.18.49~J7G5Wl", "parent_policy_id": null, "score": 0.24115016633138314, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 18:28:16.340744"}, "94": {"model_id": "2024-05-31_18.19.04~xb6yhJ", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_18.19.04~xb6yhJ", "parent_policy_id": null, "score": 0.24963097448900914, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 18:28:49.178750"}, "95": {"model_id": "2024-05-31_18.28.16~h8MNGx", "parent_model_id": "2024-05-31_17.55.27~aQwARz", "model_info": {"policy_id": "2024-05-31_18.28.16~h8MNGx", "parent_policy_id": "2024-05-31_17.55.27~aQwARz", "score": 8.68504293713915, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-05-31 18:37:23.224722"}, "96": {"model_id": "2024-05-31_18.27.52~dPfIWZ", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_18.27.52~dPfIWZ", "parent_policy_id": null, "score": 0.23398358263571623, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 18:37:26.747052"}, "97": {"model_id": "2024-05-31_18.28.49~KRJodr", "parent_model_id": "2024-05-31_17.55.27~aQwARz", "model_info": {"policy_id": "2024-05-31_18.28.49~KRJodr", "parent_policy_id": "2024-05-31_17.55.27~aQwARz", "score": 6.828890321307242, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-05-31 18:37:48.674068"}, "98": {"model_id": "2024-05-31_18.37.23~Mcgkuw", "parent_model_id": "2024-05-31_18.28.16~h8MNGx", "model_info": {"policy_id": "2024-05-31_18.37.23~Mcgkuw", "parent_policy_id": "2024-05-31_18.28.16~h8MNGx", "score": 6.292935493767897, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-05-31 18:46:38.005902"}, "99": {"model_id": "2024-05-31_18.37.26~X8lzSV", "parent_model_id": "2024-05-31_17.55.27~aQwARz", "model_info": {"policy_id": "2024-05-31_18.37.26~X8lzSV", "parent_policy_id": "2024-05-31_17.55.27~aQwARz", "score": 7.496328853707083, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-05-31 18:46:38.098922"}, "100": {"model_id": "2024-05-31_18.37.48~yXkYtY", "parent_model_id": "2024-05-31_18.28.16~h8MNGx", "model_info": {"policy_id": "2024-05-31_18.37.48~yXkYtY", "parent_policy_id": "2024-05-31_18.28.16~h8MNGx", "score": 15.992931362735476, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-05-31 18:46:57.150934"}, "101": {"model_id": "2024-05-31_18.46.38~CXD6Is", "parent_model_id": "2024-05-31_18.28.16~h8MNGx", "model_info": {"policy_id": "2024-05-31_18.46.38~CXD6Is", "parent_policy_id": "2024-05-31_18.28.16~h8MNGx", "score": 5.285847113862756, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-05-31 18:55:58.733243"}, "102": {"model_id": "2024-05-31_18.46.38~H1fadE", "parent_model_id": "2024-05-31_18.28.16~h8MNGx", "model_info": {"policy_id": "2024-05-31_18.46.38~H1fadE", "parent_policy_id": "2024-05-31_18.28.16~h8MNGx", "score": 8.573068576789726, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-05-31 18:55:58.843268"}, "103": {"model_id": "2024-05-31_18.46.57~tCvAP2", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_18.46.57~tCvAP2", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 7.427336919576259, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 18:56:11.265156"}, "104": {"model_id": "2024-05-31_18.55.58~eMt35B", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_18.55.58~eMt35B", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 4.711413392369479, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:05:26.174059"}, "105": {"model_id": "2024-05-31_18.55.58~ViJYx0", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_18.55.58~ViJYx0", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 4.483937139840324, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:05:26.277082"}, "106": {"model_id": "2024-05-31_18.56.11~rIdiMo", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_18.56.11~rIdiMo", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 9.235828900013699, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:05:27.588554"}, "107": {"model_id": "2024-05-31_19.05.27~ySSHpd", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.05.27~ySSHpd", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 5.446746252806271, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:14:15.727763"}, "108": {"model_id": "2024-05-31_19.05.26~Nhhz4q", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.05.26~Nhhz4q", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 8.755847633123853, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:14:36.223381"}, "109": {"model_id": "2024-05-31_19.05.26~4NnCdF", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.05.26~4NnCdF", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 12.37205782145087, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:14:37.246414"}, "110": {"model_id": "2024-05-31_19.14.15~PmoUDG", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.14.15~PmoUDG", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 9.009421316642133, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:23:17.496613"}, "111": {"model_id": "2024-05-31_19.14.36~IHhIV5", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.14.36~IHhIV5", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 9.605048324591753, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:23:34.521048"}, "112": {"model_id": "2024-05-31_19.14.37~F0Zdad", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.14.37~F0Zdad", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 19.55815837682797, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:23:39.060345"}, "113": {"model_id": "2024-05-31_19.23.17~vqDTaT", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.23.17~vqDTaT", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 9.836775989901842, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:32:20.140622"}, "114": {"model_id": "2024-05-31_19.23.34~Qo3tSc", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_19.23.34~Qo3tSc", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 7.899813023614845, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 19:32:42.213462"}, "115": {"model_id": "2024-05-31_19.23.39~IPKOoq", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.23.39~IPKOoq", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 5.821244720132304, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:32:47.295509"}, "116": {"model_id": "2024-05-31_19.32.20~7S58vA", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.32.20~7S58vA", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.03769762412806, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:41:16.402592"}, "117": {"model_id": "2024-05-31_19.32.42~Pl2bsI", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.32.42~Pl2bsI", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.476770080494186, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:41:30.785907"}, "118": {"model_id": "2024-05-31_19.32.47~cBehB2", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.32.47~cBehB2", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 16.603871815007082, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:41:42.665087"}, "119": {"model_id": "2024-05-31_19.41.16~DrHEZE", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.41.16~DrHEZE", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 7.568945237950194, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:50:09.670620"}, "120": {"model_id": "2024-05-31_19.41.30~P0gywa", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.41.30~P0gywa", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 11.127856274753867, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:50:26.214851"}, "121": {"model_id": "2024-05-31_19.41.42~PRXgyv", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.41.42~PRXgyv", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 12.096263269900863, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:50:31.608501"}, "122": {"model_id": "2024-05-31_19.50.09~nY8qYh", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.50.09~nY8qYh", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 9.829129817105922, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:59:02.182179"}, "123": {"model_id": "2024-05-31_19.50.31~OJlNXv", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.50.31~OJlNXv", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.240489518845262, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:59:25.191835"}, "124": {"model_id": "2024-05-31_19.50.26~NAn0Kb", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.50.26~NAn0Kb", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 14.224593740490402, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 19:59:29.524983"}, "125": {"model_id": "2024-05-31_19.59.02~AxaH7v", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.59.02~AxaH7v", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 15.54234949486679, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:08:06.181347"}, "126": {"model_id": "2024-05-31_19.59.29~DUb2ve", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.59.29~DUb2ve", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.70066512956464, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:08:37.685924"}, "127": {"model_id": "2024-05-31_19.59.25~3UcH94", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_19.59.25~3UcH94", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 7.208430359247251, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:08:40.315365"}, "128": {"model_id": "2024-05-31_20.08.06~RaFDyz", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.08.06~RaFDyz", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.710572723459354, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:17:10.876154"}, "129": {"model_id": "2024-05-31_20.08.37~0mtCfe", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.08.37~0mtCfe", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 13.980368311611475, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:17:35.105255"}, "130": {"model_id": "2024-05-31_20.08.40~UCiyAB", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.08.40~UCiyAB", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 7.68484547937268, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:17:46.543982"}, "131": {"model_id": "2024-05-31_20.17.10~wGnoVj", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.17.10~wGnoVj", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.300354916577396, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:26:19.072890"}, "132": {"model_id": "2024-05-31_20.17.35~ztHJ4U", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.17.35~ztHJ4U", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 9.869534464020578, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:26:42.005772"}, "133": {"model_id": "2024-05-31_20.17.46~7sAdxn", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.17.46~7sAdxn", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.696190075528127, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:26:54.486319"}, "134": {"model_id": "2024-05-31_20.26.19~bvgijs", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.26.19~bvgijs", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 9.199971128663718, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:35:30.936791"}, "135": {"model_id": "2024-05-31_20.26.42~KQeNc2", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.26.42~KQeNc2", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 6.639680915434605, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:35:53.599377"}, "136": {"model_id": "2024-05-31_20.26.54~A5DKOZ", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.26.54~A5DKOZ", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 13.001963283940627, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:36:06.509622"}, "137": {"model_id": "2024-05-31_20.35.31~iPiW0K", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.35.31~iPiW0K", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.756439183039728, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:44:34.138551"}, "138": {"model_id": "2024-05-31_20.35.53~QAy0EP", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.35.53~QAy0EP", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 15.294682335141175, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:44:53.987407"}, "139": {"model_id": "2024-05-31_20.36.06~MYXqt2", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.36.06~MYXqt2", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 8.526867124623985, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:45:09.979172"}, "140": {"model_id": "2024-05-31_20.44.34~Gbw01V", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.44.34~Gbw01V", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 12.974829208190878, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:53:40.041586"}, "141": {"model_id": "2024-05-31_20.44.54~H5TsPp", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.44.54~H5TsPp", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.245908074393727, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:53:58.267579"}, "142": {"model_id": "2024-05-31_20.45.10~ifEfDC", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.45.10~ifEfDC", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 6.979702565155252, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 20:54:15.509098"}, "143": {"model_id": "2024-05-31_20.53.40~XVQDpV", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.53.40~XVQDpV", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 14.809648320573253, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:02:41.340203"}, "144": {"model_id": "2024-05-31_20.53.58~GwwsUN", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.53.58~GwwsUN", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 6.023610174000862, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:02:59.430250"}, "145": {"model_id": "2024-05-31_20.54.15~T2oYk5", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_20.54.15~T2oYk5", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 4.866407944434217, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:03:16.607289"}, "146": {"model_id": "2024-05-31_21.02.41~5n2PmM", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.02.41~5n2PmM", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 11.044178095674122, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:11:38.029445"}, "147": {"model_id": "2024-05-31_21.02.59~2W5379", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.02.59~2W5379", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 7.32995623449357, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:11:54.712032"}, "148": {"model_id": "2024-05-31_21.03.16~R8RLCD", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.03.16~R8RLCD", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.546315163031412, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:12:10.716721"}, "149": {"model_id": "2024-05-31_21.11.38~KrNi3X", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.11.38~KrNi3X", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 7.210857023586503, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:20:36.075107"}, "150": {"model_id": "2024-05-31_21.11.54~mvsMrF", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.11.54~mvsMrF", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 12.72512109279611, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:20:55.273849"}, "151": {"model_id": "2024-05-31_21.12.10~bUDgWP", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.12.10~bUDgWP", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.63836840481072, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:21:09.164481"}, "152": {"model_id": "2024-05-31_21.20.36~oWK8n9", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.20.36~oWK8n9", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 5.321591561967215, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:29:40.680584"}, "153": {"model_id": "2024-05-31_21.20.55~e0lkFB", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.20.55~e0lkFB", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 18.686725343321747, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:29:59.312898"}, "154": {"model_id": "2024-05-31_21.21.09~pXFHjd", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.21.09~pXFHjd", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 14.543997676628798, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:30:12.187336"}, "155": {"model_id": "2024-05-31_21.35.20~DnUikE", "parent_model_id": "2024-05-31_21.03.16~R8RLCD", "model_info": {"policy_id": "2024-05-31_21.35.20~DnUikE", "parent_policy_id": "2024-05-31_21.03.16~R8RLCD", "score": 8.15177872813991, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 21:43:51.792610"}, "156": {"model_id": "2024-05-31_21.35.35~ho1YbB", "parent_model_id": "2024-05-31_19.50.26~NAn0Kb", "model_info": {"policy_id": "2024-05-31_21.35.35~ho1YbB", "parent_policy_id": "2024-05-31_19.50.26~NAn0Kb", "score": 18.129027677421746, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 21:44:31.693544"}, "157": {"model_id": "2024-05-31_21.35.50~FLSx4Z", "parent_model_id": "2024-05-31_19.32.47~cBehB2", "model_info": {"policy_id": "2024-05-31_21.35.50~FLSx4Z", "parent_policy_id": "2024-05-31_19.32.47~cBehB2", "score": 10.160576359317385, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 21:44:58.381202"}, "158": {"model_id": "2024-05-31_21.43.51~zgIde2", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_21.43.51~zgIde2", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 11.035494228150577, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 21:52:48.854721"}, "159": {"model_id": "2024-05-31_21.44.31~b32olQ", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_21.44.31~b32olQ", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 7.869051991082952, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 21:53:27.664753"}, "160": {"model_id": "2024-05-31_21.44.58~UxhyY5", "parent_model_id": null, "model_info": {"policy_id": "2024-05-31_21.44.58~UxhyY5", "parent_policy_id": null, "score": 0.2500684992305782, "steps_trained": 50000, "env_steps_trained": 800000, "optimizations_done": 10, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n"}, "last_update_time": "2024-05-31 21:54:10.625319"}, "161": {"model_id": "2024-05-31_21.52.48~eLt2kf", "parent_model_id": "2024-05-31_20.26.54~A5DKOZ", "model_info": {"policy_id": "2024-05-31_21.52.48~eLt2kf", "parent_policy_id": "2024-05-31_20.26.54~A5DKOZ", "score": 7.9430406319773414, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:01:53.700722"}, "162": {"model_id": "2024-05-31_21.53.27~i5hEgO", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_21.53.27~i5hEgO", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 6.358505256939784, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 22:02:31.356903"}, "163": {"model_id": "2024-05-31_21.54.10~s5MY5X", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_21.54.10~s5MY5X", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 4.377856177197428, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:03:13.274139"}, "164": {"model_id": "2024-05-31_22.01.53~X0HWh9", "parent_model_id": "2024-05-31_20.35.53~QAy0EP", "model_info": {"policy_id": "2024-05-31_22.01.53~X0HWh9", "parent_policy_id": "2024-05-31_20.35.53~QAy0EP", "score": 8.471569007387057, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:10:56.693733"}, "165": {"model_id": "2024-05-31_22.02.31~oIePgF", "parent_model_id": "2024-05-31_19.32.47~cBehB2", "model_info": {"policy_id": "2024-05-31_22.02.31~oIePgF", "parent_policy_id": "2024-05-31_19.32.47~cBehB2", "score": 17.682157703886197, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:11:27.136556"}, "166": {"model_id": "2024-05-31_22.03.13~HXTiXf", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_22.03.13~HXTiXf", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 5.0877847057845305, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 22:12:15.529140"}, "167": {"model_id": "2024-05-31_22.10.56~5D7ZtM", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.10.56~5D7ZtM", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 12.284506111924797, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:19:54.076634"}, "168": {"model_id": "2024-05-31_22.11.27~HqNj3I", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.11.27~HqNj3I", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 8.988394607032395, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:20:31.673128"}, "169": {"model_id": "2024-05-31_22.12.15~tre7HO", "parent_model_id": "2024-05-31_19.59.02~AxaH7v", "model_info": {"policy_id": "2024-05-31_22.12.15~tre7HO", "parent_policy_id": "2024-05-31_19.59.02~AxaH7v", "score": 7.685453555679219, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:21:27.476278"}, "170": {"model_id": "2024-05-31_22.19.54~OTh4z6", "parent_model_id": "2024-05-31_21.03.16~R8RLCD", "model_info": {"policy_id": "2024-05-31_22.19.54~OTh4z6", "parent_policy_id": "2024-05-31_21.03.16~R8RLCD", "score": 16.783250714592867, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:29:10.052784"}, "171": {"model_id": "2024-05-31_22.20.31~yQGlwM", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_22.20.31~yQGlwM", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 10.564160830313575, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 22:29:48.153506"}, "172": {"model_id": "2024-05-31_22.21.27~xzHVQq", "parent_model_id": "2024-05-31_20.26.54~A5DKOZ", "model_info": {"policy_id": "2024-05-31_22.21.27~xzHVQq", "parent_policy_id": "2024-05-31_20.26.54~A5DKOZ", "score": 5.706385318721349, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:30:49.283336"}, "173": {"model_id": "2024-05-31_22.29.10~vr09Xu", "parent_model_id": "2024-05-31_19.14.37~F0Zdad", "model_info": {"policy_id": "2024-05-31_22.29.10~vr09Xu", "parent_policy_id": "2024-05-31_19.14.37~F0Zdad", "score": 5.41414063532757, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-05-31 22:38:18.681785"}, "174": {"model_id": "2024-05-31_22.29.48~7E46Oe", "parent_model_id": "2024-05-31_20.35.53~QAy0EP", "model_info": {"policy_id": "2024-05-31_22.29.48~7E46Oe", "parent_policy_id": "2024-05-31_20.35.53~QAy0EP", "score": 12.469722906278164, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:38:56.652121"}, "175": {"model_id": "2024-05-31_22.30.49~ZePYHI", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.30.49~ZePYHI", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 6.242007322308572, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:40:00.388323"}, "176": {"model_id": "2024-05-31_22.38.18~3fqeRc", "parent_model_id": "2024-05-31_22.10.56~5D7ZtM", "model_info": {"policy_id": "2024-05-31_22.38.18~3fqeRc", "parent_policy_id": "2024-05-31_22.10.56~5D7ZtM", "score": 10.016183538786173, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 22:47:22.189592"}, "177": {"model_id": "2024-05-31_22.38.56~1L0ek8", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.38.56~1L0ek8", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 10.297239969452553, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:48:03.248055"}, "178": {"model_id": "2024-05-31_22.40.00~6uUEXw", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.40.00~6uUEXw", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 4.776479768043357, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:49:23.786630"}, "179": {"model_id": "2024-05-31_22.47.22~J0CwP3", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_22.47.22~J0CwP3", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 5.773999633508836, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:56:50.105293"}, "180": {"model_id": "2024-05-31_22.48.03~zFrFDX", "parent_model_id": "2024-05-31_18.37.48~yXkYtY", "model_info": {"policy_id": "2024-05-31_22.48.03~zFrFDX", "parent_policy_id": "2024-05-31_18.37.48~yXkYtY", "score": 14.487766613766219, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-05-31 22:57:22.900841"}, "181": {"model_id": "2024-05-31_22.49.23~JtrQRc", "parent_model_id": "2024-05-31_19.41.42~PRXgyv", "model_info": {"policy_id": "2024-05-31_22.49.23~JtrQRc", "parent_policy_id": "2024-05-31_19.41.42~PRXgyv", "score": 6.69714111694633, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 22:58:46.008717"}, "182": {"model_id": "2024-05-31_22.56.50~GHlyCc", "parent_model_id": "2024-05-31_19.59.02~AxaH7v", "model_info": {"policy_id": "2024-05-31_22.56.50~GHlyCc", "parent_policy_id": "2024-05-31_19.59.02~AxaH7v", "score": 13.984897479223878, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:06:13.233768"}, "183": {"model_id": "2024-05-31_22.57.23~oluJ9I", "parent_model_id": "2024-05-31_22.19.54~OTh4z6", "model_info": {"policy_id": "2024-05-31_22.57.23~oluJ9I", "parent_policy_id": "2024-05-31_22.19.54~OTh4z6", "score": 8.537304531004056, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:06:42.204828"}, "184": {"model_id": "2024-05-31_22.58.46~zTgaRt", "parent_model_id": "2024-05-31_20.26.54~A5DKOZ", "model_info": {"policy_id": "2024-05-31_22.58.46~zTgaRt", "parent_policy_id": "2024-05-31_20.26.54~A5DKOZ", "score": 9.048910003634152, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:07:49.686055"}, "185": {"model_id": "2024-05-31_23.06.13~ynb1Xd", "parent_model_id": "2024-05-31_20.35.53~QAy0EP", "model_info": {"policy_id": "2024-05-31_23.06.13~ynb1Xd", "parent_policy_id": "2024-05-31_20.35.53~QAy0EP", "score": 6.959291185066782, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:15:04.173318"}, "186": {"model_id": "2024-05-31_23.06.42~Vn8Trr", "parent_model_id": "2024-05-31_22.02.31~oIePgF", "model_info": {"policy_id": "2024-05-31_23.06.42~Vn8Trr", "parent_policy_id": "2024-05-31_22.02.31~oIePgF", "score": 12.266992447515921, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:15:26.742098"}, "187": {"model_id": "2024-05-31_23.07.49~IvY1uW", "parent_model_id": "2024-05-31_22.19.54~OTh4z6", "model_info": {"policy_id": "2024-05-31_23.07.49~IvY1uW", "parent_policy_id": "2024-05-31_22.19.54~OTh4z6", "score": 6.186134796113827, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:16:44.108722"}, "188": {"model_id": "2024-05-31_23.15.04~RCcU0r", "parent_model_id": "2024-05-31_20.53.40~XVQDpV", "model_info": {"policy_id": "2024-05-31_23.15.04~RCcU0r", "parent_policy_id": "2024-05-31_20.53.40~XVQDpV", "score": 5.365195728340799, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:24:18.113042"}, "189": {"model_id": "2024-05-31_23.15.26~7SslrA", "parent_model_id": "2024-05-31_22.19.54~OTh4z6", "model_info": {"policy_id": "2024-05-31_23.15.26~7SslrA", "parent_policy_id": "2024-05-31_22.19.54~OTh4z6", "score": 15.816113925788283, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:24:40.565612"}, "190": {"model_id": "2024-05-31_23.16.44~VyhMyf", "parent_model_id": "2024-05-31_22.02.31~oIePgF", "model_info": {"policy_id": "2024-05-31_23.16.44~VyhMyf", "parent_policy_id": "2024-05-31_22.02.31~oIePgF", "score": 9.762117574828817, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:25:59.424876"}, "191": {"model_id": "2024-05-31_23.24.18~4XhHs1", "parent_model_id": "2024-05-31_21.20.55~e0lkFB", "model_info": {"policy_id": "2024-05-31_23.24.18~4XhHs1", "parent_policy_id": "2024-05-31_21.20.55~e0lkFB", "score": 15.397333995143924, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:33:32.923687"}, "192": {"model_id": "2024-05-31_23.24.40~YCK2dJ", "parent_model_id": "2024-05-31_22.21.27~xzHVQq", "model_info": {"policy_id": "2024-05-31_23.24.40~YCK2dJ", "parent_policy_id": "2024-05-31_22.21.27~xzHVQq", "score": 7.152288432459608, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:33:55.599329"}, "193": {"model_id": "2024-05-31_23.25.59~rQgVHu", "parent_model_id": "2024-05-31_21.11.54~mvsMrF", "model_info": {"policy_id": "2024-05-31_23.25.59~rQgVHu", "parent_policy_id": "2024-05-31_21.11.54~mvsMrF", "score": 8.795997521700638, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:35:10.501082"}, "194": {"model_id": "2024-05-31_23.46.49~Ez0IUN", "parent_model_id": "2024-05-31_23.15.26~7SslrA", "model_info": {"policy_id": "2024-05-31_23.46.49~Ez0IUN", "parent_policy_id": "2024-05-31_23.15.26~7SslrA", "score": 12.733023438091891, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-05-31 23:55:35.605546"}, "195": {"model_id": "2024-05-31_23.47.07~XzYG5I", "parent_model_id": "2024-05-31_23.24.18~4XhHs1", "model_info": {"policy_id": "2024-05-31_23.47.07~XzYG5I", "parent_policy_id": "2024-05-31_23.24.18~4XhHs1", "score": 14.805496721549424, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-05-31 23:56:00.797603"}, "196": {"model_id": "2024-05-31_23.47.22~iyFiPn", "parent_model_id": "2024-05-31_19.41.30~P0gywa", "model_info": {"policy_id": "2024-05-31_23.47.22~iyFiPn", "parent_policy_id": "2024-05-31_19.41.30~P0gywa", "score": 12.043149879080616, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-05-31 23:56:19.430200"}, "197": {"model_id": "2024-05-31_23.55.35~3jvzTu", "parent_model_id": "2024-05-31_22.19.54~OTh4z6", "model_info": {"policy_id": "2024-05-31_23.55.35~3jvzTu", "parent_policy_id": "2024-05-31_22.19.54~OTh4z6", "score": 16.33705205231572, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 00:04:20.236620"}, "198": {"model_id": "2024-05-31_23.56.00~FXRGCp", "parent_model_id": "2024-05-31_19.32.47~cBehB2", "model_info": {"policy_id": "2024-05-31_23.56.00~FXRGCp", "parent_policy_id": "2024-05-31_19.32.47~cBehB2", "score": 15.839356249397307, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 00:04:53.444444"}, "199": {"model_id": "2024-05-31_23.56.19~n28nNU", "parent_model_id": "2024-05-31_19.32.47~cBehB2", "model_info": {"policy_id": "2024-05-31_23.56.19~n28nNU", "parent_policy_id": "2024-05-31_19.32.47~cBehB2", "score": 7.4862950630569145, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 00:05:15.167509"}, "200": {"model_id": "2024-06-01_00.04.20~R4tnR3", "parent_model_id": "2024-05-31_21.35.35~ho1YbB", "model_info": {"policy_id": "2024-06-01_00.04.20~R4tnR3", "parent_policy_id": "2024-05-31_21.35.35~ho1YbB", "score": 17.12841339329256, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 00:13:06.168936"}, "201": {"model_id": "2024-06-01_00.04.53~4PXr37", "parent_model_id": "2024-05-31_23.24.18~4XhHs1", "model_info": {"policy_id": "2024-06-01_00.04.53~4PXr37", "parent_policy_id": "2024-05-31_23.24.18~4XhHs1", "score": 9.941782570735397, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 00:13:43.913949"}, "202": {"model_id": "2024-06-01_00.05.15~avjFW3", "parent_model_id": "2024-05-31_23.55.35~3jvzTu", "model_info": {"policy_id": "2024-06-01_00.05.15~avjFW3", "parent_policy_id": "2024-05-31_23.55.35~3jvzTu", "score": 10.095353001525318, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 00:14:08.785117"}}}
{"_default": {"1": {"model_id": "2024-05-28_23.10.15~6QVFyI", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.10.15~6QVFyI", "parent_policy_id": null, "score": 0.02756274780800832, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:53.854891"}, "2": {"model_id": "2024-05-28_23.17.44~QlbUFa", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.17.44~QlbUFa", "parent_policy_id": null, "score": 0.03390417024646837, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:53.932907"}, "3": {"model_id": "2024-05-28_23.18.28~rlRteB", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.18.28~rlRteB", "parent_policy_id": null, "score": 0.03419302204001851, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:54.011927"}, "4": {"model_id": "2024-05-28_23.25.50~AZeaFt", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.25.50~AZeaFt", "parent_policy_id": null, "score": 0.03560724578418207, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:54.099947"}, "5": {"model_id": "2024-05-28_23.33.35~CUWu2J", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.33.35~CUWu2J", "parent_policy_id": null, "score": 0.035249084915019886, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:54.206972"}, "6": {"model_id": "2024-05-28_23.41.43~p5yas3", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.41.43~p5yas3", "parent_policy_id": null, "score": 0.03, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 00:55:54.317998"}, "7": {"model_id": "2024-06-01_01.11.56~NpUIqs", "parent_model_id": "2024-05-28_23.10.15~6QVFyI", "model_info": {"policy_id": "2024-06-01_01.11.56~NpUIqs", "parent_policy_id": "2024-05-28_23.10.15~6QVFyI", "score": 2.002335553233679, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 01:21:27.942373"}, "8": {"model_id": "2024-06-01_01.12.14~Am6OuX", "parent_model_id": "2024-05-28_23.33.35~CUWu2J", "model_info": {"policy_id": "2024-06-01_01.12.14~Am6OuX", "parent_policy_id": "2024-05-28_23.33.35~CUWu2J", "score": 1.9301210944093434, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 01:21:52.153167"}, "9": {"model_id": "2024-06-01_01.12.29~ZP7eld", "parent_model_id": "2024-05-28_23.18.28~rlRteB", "model_info": {"policy_id": "2024-06-01_01.12.29~ZP7eld", "parent_policy_id": "2024-05-28_23.18.28~rlRteB", "score": 2.1314960824485616, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 01:22:25.137811"}, "10": {"model_id": "2024-06-01_01.21.28~5KQTdJ", "parent_model_id": "2024-06-01_01.11.56~NpUIqs", "model_info": {"policy_id": "2024-06-01_01.21.28~5KQTdJ", "parent_policy_id": "2024-06-01_01.11.56~NpUIqs", "score": 2.022649438312824, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 01:31:11.587345"}, "11": {"model_id": "2024-06-01_01.21.52~qkwmxm", "parent_model_id": "2024-06-01_01.12.14~Am6OuX", "model_info": {"policy_id": "2024-06-01_01.21.52~qkwmxm", "parent_policy_id": "2024-06-01_01.12.14~Am6OuX", "score": 2.219419617274223, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 01:31:29.874351"}, "12": {"model_id": "2024-06-01_01.22.25~2aHyiX", "parent_model_id": "2024-06-01_01.12.14~Am6OuX", "model_info": {"policy_id": "2024-06-01_01.22.25~2aHyiX", "parent_policy_id": "2024-06-01_01.12.14~Am6OuX", "score": 2.6499356849710147, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 01:32:08.466511"}, "13": {"model_id": "2024-06-01_01.31.11~Gd1ab7", "parent_model_id": "2024-05-28_23.18.28~rlRteB", "model_info": {"policy_id": "2024-06-01_01.31.11~Gd1ab7", "parent_policy_id": "2024-05-28_23.18.28~rlRteB", "score": 1.8981682797688664, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 01:40:54.426524"}, "14": {"model_id": "2024-06-01_01.31.30~p9v6l6", "parent_model_id": "2024-06-01_01.21.28~5KQTdJ", "model_info": {"policy_id": "2024-06-01_01.31.30~p9v6l6", "parent_policy_id": "2024-06-01_01.21.28~5KQTdJ", "score": 1.9770885518064008, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 01:41:08.350763"}, "15": {"model_id": "2024-06-01_01.32.08~HuruKW", "parent_model_id": "2024-06-01_01.21.28~5KQTdJ", "model_info": {"policy_id": "2024-06-01_01.32.08~HuruKW", "parent_policy_id": "2024-06-01_01.21.28~5KQTdJ", "score": 2.461248844796615, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 01:41:44.963175"}, "16": {"model_id": "2024-06-01_01.40.54~uzcYBv", "parent_model_id": "2024-06-01_01.31.11~Gd1ab7", "model_info": {"policy_id": "2024-06-01_01.40.54~uzcYBv", "parent_policy_id": "2024-06-01_01.31.11~Gd1ab7", "score": 3.049410971911344, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 01:50:32.399194"}, "17": {"model_id": "2024-06-01_01.41.08~17KoZu", "parent_model_id": "2024-05-28_23.33.35~CUWu2J", "model_info": {"policy_id": "2024-06-01_01.41.08~17KoZu", "parent_policy_id": "2024-05-28_23.33.35~CUWu2J", "score": 1.6637634939667039, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 01:50:46.471977"}, "18": {"model_id": "2024-06-01_01.41.45~QxVGze", "parent_model_id": "2024-06-01_01.31.11~Gd1ab7", "model_info": {"policy_id": "2024-06-01_01.41.45~QxVGze", "parent_policy_id": "2024-06-01_01.31.11~Gd1ab7", "score": 3.069645805306713, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 01:51:24.713538"}, "19": {"model_id": "2024-06-01_01.50.32~1nzCVY", "parent_model_id": "2024-06-01_01.12.14~Am6OuX", "model_info": {"policy_id": "2024-06-01_01.50.32~1nzCVY", "parent_policy_id": "2024-06-01_01.12.14~Am6OuX", "score": 2.336383911468654, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 02:00:13.227212"}, "20": {"model_id": "2024-06-01_01.50.46~uitSvy", "parent_model_id": "2024-06-01_01.21.52~qkwmxm", "model_info": {"policy_id": "2024-06-01_01.50.46~uitSvy", "parent_policy_id": "2024-06-01_01.21.52~qkwmxm", "score": 2.5472608092222204, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:00:22.226952"}, "21": {"model_id": "2024-06-01_01.51.24~s8uzjj", "parent_model_id": "2024-06-01_01.41.45~QxVGze", "model_info": {"policy_id": "2024-06-01_01.51.24~s8uzjj", "parent_policy_id": "2024-06-01_01.41.45~QxVGze", "score": 4.131137727427431, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:01:05.821823"}, "22": {"model_id": "2024-06-01_02.00.13~Ya89fb", "parent_model_id": "2024-06-01_01.32.08~HuruKW", "model_info": {"policy_id": "2024-06-01_02.00.13~Ya89fb", "parent_policy_id": "2024-06-01_01.32.08~HuruKW", "score": 3.97585216479949, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:09:57.622505"}, "23": {"model_id": "2024-06-01_02.00.22~ioTPxS", "parent_model_id": "2024-06-01_01.50.46~uitSvy", "model_info": {"policy_id": "2024-06-01_02.00.22~ioTPxS", "parent_policy_id": "2024-06-01_01.50.46~uitSvy", "score": 3.244071783517402, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:10:10.942390"}, "24": {"model_id": "2024-06-01_02.01.05~A9l6nj", "parent_model_id": "2024-06-01_01.22.25~2aHyiX", "model_info": {"policy_id": "2024-06-01_02.01.05~A9l6nj", "parent_policy_id": "2024-06-01_01.22.25~2aHyiX", "score": 3.3901598057631785, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:11:09.209643"}, "25": {"model_id": "2024-06-01_02.09.57~910QSc", "parent_model_id": "2024-06-01_01.40.54~uzcYBv", "model_info": {"policy_id": "2024-06-01_02.09.57~910QSc", "parent_policy_id": "2024-06-01_01.40.54~uzcYBv", "score": 2.6814143683409317, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:19:24.115492"}, "26": {"model_id": "2024-06-01_02.10.11~encrEW", "parent_model_id": "2024-06-01_02.00.13~Ya89fb", "model_info": {"policy_id": "2024-06-01_02.10.11~encrEW", "parent_policy_id": "2024-06-01_02.00.13~Ya89fb", "score": 3.086370307604113, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 02:19:45.699727"}, "27": {"model_id": "2024-06-01_02.11.09~TQ9mvP", "parent_model_id": "2024-06-01_02.00.22~ioTPxS", "model_info": {"policy_id": "2024-06-01_02.11.09~TQ9mvP", "parent_policy_id": "2024-06-01_02.00.22~ioTPxS", "score": 3.1616613330882637, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 02:20:44.160273"}, "28": {"model_id": "2024-06-01_02.19.24~pnNiTk", "parent_model_id": "2024-06-01_01.22.25~2aHyiX", "model_info": {"policy_id": "2024-06-01_02.19.24~pnNiTk", "parent_policy_id": "2024-06-01_01.22.25~2aHyiX", "score": 3.0237764578239252, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:28:36.193191"}, "29": {"model_id": "2024-06-01_02.19.45~rP5lWT", "parent_model_id": "2024-06-01_01.11.56~NpUIqs", "model_info": {"policy_id": "2024-06-01_02.19.45~rP5lWT", "parent_policy_id": "2024-06-01_01.11.56~NpUIqs", "score": 1.9750975864819358, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 02:28:58.655912"}, "30": {"model_id": "2024-06-01_02.20.44~1nC7FG", "parent_model_id": "2024-06-01_01.21.28~5KQTdJ", "model_info": {"policy_id": "2024-06-01_02.20.44~1nC7FG", "parent_policy_id": "2024-06-01_01.21.28~5KQTdJ", "score": 2.028378013236981, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:30:00.848217"}, "31": {"model_id": "2024-06-01_02.28.36~czdxw6", "parent_model_id": "2024-06-01_02.00.13~Ya89fb", "model_info": {"policy_id": "2024-06-01_02.28.36~czdxw6", "parent_policy_id": "2024-06-01_02.00.13~Ya89fb", "score": 3.059471123155352, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 02:37:48.212084"}, "32": {"model_id": "2024-06-01_02.28.58~9oLwih", "parent_model_id": "2024-06-01_01.40.54~uzcYBv", "model_info": {"policy_id": "2024-06-01_02.28.58~9oLwih", "parent_policy_id": "2024-06-01_01.40.54~uzcYBv", "score": 2.847582598742465, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 30}, "last_update_time": "2024-06-01 02:38:13.732415"}, "33": {"model_id": "2024-06-01_02.30.01~sGtTNf", "parent_model_id": "2024-06-01_01.50.46~uitSvy", "model_info": {"policy_id": "2024-06-01_02.30.01~sGtTNf", "parent_policy_id": "2024-06-01_01.50.46~uitSvy", "score": 3.4279689260266846, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:39:14.874681"}, "34": {"model_id": "2024-06-01_02.37.48~kiyN8D", "parent_model_id": "2024-06-01_02.10.11~encrEW", "model_info": {"policy_id": "2024-06-01_02.37.48~kiyN8D", "parent_policy_id": "2024-06-01_02.10.11~encrEW", "score": 5.287090409385643, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 02:46:59.172108"}, "35": {"model_id": "2024-06-01_02.38.13~MODn8S", "parent_model_id": "2024-06-01_01.51.24~s8uzjj", "model_info": {"policy_id": "2024-06-01_02.38.13~MODn8S", "parent_policy_id": "2024-06-01_01.51.24~s8uzjj", "score": 4.290618779161715, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:47:25.934656"}, "36": {"model_id": "2024-06-01_02.39.15~8t4Ir2", "parent_model_id": "2024-06-01_02.09.57~910QSc", "model_info": {"policy_id": "2024-06-01_02.39.15~8t4Ir2", "parent_policy_id": "2024-06-01_02.09.57~910QSc", "score": 3.6407000757425987, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:48:28.162719"}, "37": {"model_id": "2024-06-01_02.46.59~2AsIxk", "parent_model_id": "2024-06-01_02.10.11~encrEW", "model_info": {"policy_id": "2024-06-01_02.46.59~2AsIxk", "parent_policy_id": "2024-06-01_02.10.11~encrEW", "score": 5.0836420390450945, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 02:56:09.521235"}, "38": {"model_id": "2024-06-01_02.47.26~CXbx8d", "parent_model_id": "2024-06-01_02.11.09~TQ9mvP", "model_info": {"policy_id": "2024-06-01_02.47.26~CXbx8d", "parent_policy_id": "2024-06-01_02.11.09~TQ9mvP", "score": 3.74303679110692, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 02:56:32.486992"}, "39": {"model_id": "2024-06-01_02.48.28~g5WuGx", "parent_model_id": "2024-06-01_01.51.24~s8uzjj", "model_info": {"policy_id": "2024-06-01_02.48.28~g5WuGx", "parent_policy_id": "2024-06-01_01.51.24~s8uzjj", "score": 3.666678374403026, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 02:57:36.920647"}, "40": {"model_id": "2024-06-01_02.56.09~qfeniy", "parent_model_id": "2024-06-01_02.01.05~A9l6nj", "model_info": {"policy_id": "2024-06-01_02.56.09~qfeniy", "parent_policy_id": "2024-06-01_02.01.05~A9l6nj", "score": 4.027220981002186, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 03:05:16.956188"}, "41": {"model_id": "2024-06-01_02.56.32~aXGTCN", "parent_model_id": "2024-06-01_02.38.13~MODn8S", "model_info": {"policy_id": "2024-06-01_02.56.32~aXGTCN", "parent_policy_id": "2024-06-01_02.38.13~MODn8S", "score": 4.427673796175501, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 03:05:44.212866"}, "42": {"model_id": "2024-06-01_02.57.37~0VZDxc", "parent_model_id": "2024-06-01_02.46.59~2AsIxk", "model_info": {"policy_id": "2024-06-01_02.57.37~0VZDxc", "parent_policy_id": "2024-06-01_02.46.59~2AsIxk", "score": 3.948652375591472, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 03:06:48.337531"}, "43": {"model_id": "2024-06-01_03.05.17~GykmtJ", "parent_model_id": "2024-06-01_02.28.58~9oLwih", "model_info": {"policy_id": "2024-06-01_03.05.17~GykmtJ", "parent_policy_id": "2024-06-01_02.28.58~9oLwih", "score": 3.1397144072158163, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 03:14:28.180269"}, "44": {"model_id": "2024-06-01_03.05.44~VSxpgs", "parent_model_id": "2024-06-01_02.37.48~kiyN8D", "model_info": {"policy_id": "2024-06-01_03.05.44~VSxpgs", "parent_policy_id": "2024-06-01_02.37.48~kiyN8D", "score": 5.7500812840384175, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 03:14:53.774363"}, "45": {"model_id": "2024-06-01_03.06.48~qjrQ5V", "parent_model_id": "2024-06-01_02.28.36~czdxw6", "model_info": {"policy_id": "2024-06-01_03.06.48~qjrQ5V", "parent_policy_id": "2024-06-01_02.28.36~czdxw6", "score": 3.294212905398914, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 03:15:59.805368"}, "46": {"model_id": "2024-06-01_03.14.28~BY5svs", "parent_model_id": "2024-06-01_02.28.36~czdxw6", "model_info": {"policy_id": "2024-06-01_03.14.28~BY5svs", "parent_policy_id": "2024-06-01_02.28.36~czdxw6", "score": 3.9891307292281493, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 03:23:33.439889"}, "47": {"model_id": "2024-06-01_03.14.53~x88AMC", "parent_model_id": "2024-06-01_01.32.08~HuruKW", "model_info": {"policy_id": "2024-06-01_03.14.53~x88AMC", "parent_policy_id": "2024-06-01_01.32.08~HuruKW", "score": 3.0585511976941206, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 03:23:58.050815"}, "48": {"model_id": "2024-06-01_03.15.59~Nk85Yi", "parent_model_id": "2024-06-01_02.30.01~sGtTNf", "model_info": {"policy_id": "2024-06-01_03.15.59~Nk85Yi", "parent_policy_id": "2024-06-01_02.30.01~sGtTNf", "score": 4.23106053359715, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 03:25:06.245671"}, "49": {"model_id": "2024-06-01_03.23.33~fHCXt9", "parent_model_id": "2024-06-01_02.39.15~8t4Ir2", "model_info": {"policy_id": "2024-06-01_03.23.33~fHCXt9", "parent_policy_id": "2024-06-01_02.39.15~8t4Ir2", "score": 3.4534444968839075, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 03:32:39.842339"}, "50": {"model_id": "2024-06-01_03.23.58~Gr3y5u", "parent_model_id": "2024-06-01_01.31.30~p9v6l6", "model_info": {"policy_id": "2024-06-01_03.23.58~Gr3y5u", "parent_policy_id": "2024-06-01_01.31.30~p9v6l6", "score": 2.429205280268216, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 03:33:06.104316"}, "51": {"model_id": "2024-06-01_03.25.06~Pw2nF8", "parent_model_id": "2024-06-01_02.47.26~CXbx8d", "model_info": {"policy_id": "2024-06-01_03.25.06~Pw2nF8", "parent_policy_id": "2024-06-01_02.47.26~CXbx8d", "score": 5.4383433021699465, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 03:34:11.615726"}, "52": {"model_id": "2024-06-01_14.57.29~4XqHkv", "parent_model_id": "2024-06-01_02.56.09~qfeniy", "model_info": {"policy_id": "2024-06-01_14.57.29~4XqHkv", "parent_policy_id": "2024-06-01_02.56.09~qfeniy", "score": 3.865332639471287, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 15:06:14.450533"}, "53": {"model_id": "2024-06-01_14.57.53~JDf6ao", "parent_model_id": "2024-06-01_03.25.06~Pw2nF8", "model_info": {"policy_id": "2024-06-01_14.57.53~JDf6ao", "parent_policy_id": "2024-06-01_03.25.06~Pw2nF8", "score": 8.030568558467529, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 15:06:55.815005"}, "54": {"model_id": "2024-06-01_14.58.13~Ajmx8t", "parent_model_id": "2024-06-01_03.14.28~BY5svs", "model_info": {"policy_id": "2024-06-01_14.58.13~Ajmx8t", "parent_policy_id": "2024-06-01_03.14.28~BY5svs", "score": 5.455647689304964, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 15:07:23.115506"}, "55": {"model_id": "2024-06-01_15.06.14~1NyIvo", "parent_model_id": "2024-06-01_02.46.59~2AsIxk", "model_info": {"policy_id": "2024-06-01_15.06.14~1NyIvo", "parent_policy_id": "2024-06-01_02.46.59~2AsIxk", "score": 4.531968913781012, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 15:15:15.410349"}, "56": {"model_id": "2024-06-01_15.06.55~o02t0l", "parent_model_id": "2024-06-01_14.57.53~JDf6ao", "model_info": {"policy_id": "2024-06-01_15.06.55~o02t0l", "parent_policy_id": "2024-06-01_14.57.53~JDf6ao", "score": 6.268712816298619, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 15:15:58.740987"}, "57": {"model_id": "2024-06-01_15.07.23~c3jdkJ", "parent_model_id": "2024-06-01_14.57.53~JDf6ao", "model_info": {"policy_id": "2024-06-01_15.07.23~c3jdkJ", "parent_policy_id": "2024-06-01_14.57.53~JDf6ao", "score": 5.197248849368958, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 15:16:27.344902"}, "58": {"model_id": "2024-06-01_15.15.15~bAlnRa", "parent_model_id": "2024-06-01_14.57.53~JDf6ao", "model_info": {"policy_id": "2024-06-01_15.15.15~bAlnRa", "parent_policy_id": "2024-06-01_14.57.53~JDf6ao", "score": 10.937694424675733, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 15:24:20.672394"}, "59": {"model_id": "2024-06-01_15.15.58~pbxb0q", "parent_model_id": "2024-06-01_14.57.53~JDf6ao", "model_info": {"policy_id": "2024-06-01_15.15.58~pbxb0q", "parent_policy_id": "2024-06-01_14.57.53~JDf6ao", "score": 6.731748473033544, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 15:25:03.807191"}, "60": {"model_id": "2024-06-01_15.16.27~ZPiFnd", "parent_model_id": "2024-06-01_15.07.23~c3jdkJ", "model_info": {"policy_id": "2024-06-01_15.16.27~ZPiFnd", "parent_policy_id": "2024-06-01_15.07.23~c3jdkJ", "score": 12.261157826294028, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 15:25:32.064313"}, "61": {"model_id": "2024-06-01_15.24.20~pFwGQH", "parent_model_id": "2024-06-01_15.15.15~bAlnRa", "model_info": {"policy_id": "2024-06-01_15.24.20~pFwGQH", "parent_policy_id": "2024-06-01_15.15.15~bAlnRa", "score": 7.990790588375672, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 15:33:21.552756"}, "62": {"model_id": "2024-06-01_15.25.03~bCeVoN", "parent_model_id": "2024-06-01_15.15.15~bAlnRa", "model_info": {"policy_id": "2024-06-01_15.25.03~bCeVoN", "parent_policy_id": "2024-06-01_15.15.15~bAlnRa", "score": 9.840250906459183, "steps_trained": 1100000, "env_steps_trained": 20800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 15:34:06.471369"}, "63": {"model_id": "2024-06-01_15.25.32~YnT25l", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.25.32~YnT25l", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 5.712744087257363, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 15:34:31.675853"}, "64": {"model_id": "2024-06-01_15.33.21~nFN4MA", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.33.21~nFN4MA", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 10.95513481055816, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 15:42:26.772033"}, "65": {"model_id": "2024-06-01_15.34.06~ZkTCox", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.34.06~ZkTCox", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 10.223049558027583, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 15:43:16.253468"}, "66": {"model_id": "2024-06-01_15.34.31~mO9siU", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.34.31~mO9siU", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 6.730624454566673, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 15:43:28.344128"}, "67": {"model_id": "2024-06-01_15.42.26~Dz1Heg", "parent_model_id": "2024-06-01_15.33.21~nFN4MA", "model_info": {"policy_id": "2024-06-01_15.42.26~Dz1Heg", "parent_policy_id": "2024-06-01_15.33.21~nFN4MA", "score": 10.376980953816764, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 15:51:07.480266"}, "68": {"model_id": "2024-06-01_15.43.16~udV4Ug", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.43.16~udV4Ug", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 11.745985911705596, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 15:52:14.095040"}, "69": {"model_id": "2024-06-01_15.43.28~oPNYPH", "parent_model_id": "2024-06-01_15.33.21~nFN4MA", "model_info": {"policy_id": "2024-06-01_15.43.28~oPNYPH", "parent_policy_id": "2024-06-01_15.33.21~nFN4MA", "score": 11.493209924066562, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 15:52:21.224062"}, "70": {"model_id": "2024-06-01_15.51.07~9lbqHW", "parent_model_id": "2024-06-01_15.42.26~Dz1Heg", "model_info": {"policy_id": "2024-06-01_15.51.07~9lbqHW", "parent_policy_id": "2024-06-01_15.42.26~Dz1Heg", "score": 6.096952752546644, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:00:03.334476"}, "71": {"model_id": "2024-06-01_15.52.14~RQWsc8", "parent_model_id": "2024-06-01_15.43.16~udV4Ug", "model_info": {"policy_id": "2024-06-01_15.52.14~RQWsc8", "parent_policy_id": "2024-06-01_15.43.16~udV4Ug", "score": 11.332578404651981, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 16:01:18.899168"}, "72": {"model_id": "2024-06-01_15.52.21~67CTkl", "parent_model_id": "2024-06-01_15.16.27~ZPiFnd", "model_info": {"policy_id": "2024-06-01_15.52.21~67CTkl", "parent_policy_id": "2024-06-01_15.16.27~ZPiFnd", "score": 10.258771613900374, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 16:01:23.764324"}, "73": {"model_id": "2024-06-01_16.00.03~iDSKRh", "parent_model_id": "2024-06-01_15.43.16~udV4Ug", "model_info": {"policy_id": "2024-06-01_16.00.03~iDSKRh", "parent_policy_id": "2024-06-01_15.43.16~udV4Ug", "score": 13.821738473207553, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 16:08:59.111450"}, "74": {"model_id": "2024-06-01_16.01.23~xiZEvQ", "parent_model_id": "2024-06-01_15.43.16~udV4Ug", "model_info": {"policy_id": "2024-06-01_16.01.23~xiZEvQ", "parent_policy_id": "2024-06-01_15.43.16~udV4Ug", "score": 9.577801136337012, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 16:10:08.365331"}, "75": {"model_id": "2024-06-01_16.01.19~fKzwbp", "parent_model_id": "2024-06-01_15.43.28~oPNYPH", "model_info": {"policy_id": "2024-06-01_16.01.19~fKzwbp", "parent_policy_id": "2024-06-01_15.43.28~oPNYPH", "score": 9.203807085085268, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:10:14.247345"}, "76": {"model_id": "2024-06-01_16.08.59~FszYW7", "parent_model_id": "2024-06-01_16.00.03~iDSKRh", "model_info": {"policy_id": "2024-06-01_16.08.59~FszYW7", "parent_policy_id": "2024-06-01_16.00.03~iDSKRh", "score": 8.394196572511632, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:17:52.300349"}, "77": {"model_id": "2024-06-01_16.10.08~82CFFx", "parent_model_id": "2024-06-01_16.00.03~iDSKRh", "model_info": {"policy_id": "2024-06-01_16.10.08~82CFFx", "parent_policy_id": "2024-06-01_16.00.03~iDSKRh", "score": 9.482750417853385, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:19:01.818841"}, "78": {"model_id": "2024-06-01_16.10.14~ZZAb6N", "parent_model_id": "2024-06-01_16.00.03~iDSKRh", "model_info": {"policy_id": "2024-06-01_16.10.14~ZZAb6N", "parent_policy_id": "2024-06-01_16.00.03~iDSKRh", "score": 10.325684452610862, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:19:13.051491"}, "79": {"model_id": "2024-06-01_16.17.52~G4Y5Z5", "parent_model_id": "2024-06-01_16.00.03~iDSKRh", "model_info": {"policy_id": "2024-06-01_16.17.52~G4Y5Z5", "parent_policy_id": "2024-06-01_16.00.03~iDSKRh", "score": 18.08273326789309, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:26:31.595624"}, "80": {"model_id": "2024-06-01_16.19.01~CRN6Jg", "parent_model_id": "2024-06-01_16.00.03~iDSKRh", "model_info": {"policy_id": "2024-06-01_16.19.01~CRN6Jg", "parent_policy_id": "2024-06-01_16.00.03~iDSKRh", "score": 7.536654875655305, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:27:42.699392"}, "81": {"model_id": "2024-06-01_16.19.13~F6K5he", "parent_model_id": "2024-06-01_15.52.14~RQWsc8", "model_info": {"policy_id": "2024-06-01_16.19.13~F6K5he", "parent_policy_id": "2024-06-01_15.52.14~RQWsc8", "score": 8.10026184275711, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 16:27:59.958157"}, "82": {"model_id": "2024-06-01_16.26.31~KsFYc9", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.26.31~KsFYc9", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 9.1547868286043, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:35:45.700724"}, "83": {"model_id": "2024-06-01_16.27.42~5cNWsJ", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.27.42~5cNWsJ", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 7.0300948991294145, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:36:55.806442"}, "84": {"model_id": "2024-06-01_16.28.00~MrEWiD", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.28.00~MrEWiD", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 6.180219664248254, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:37:11.428221"}, "85": {"model_id": "2024-06-01_16.35.45~6uDZj0", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.35.45~6uDZj0", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 13.912780185719582, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:44:55.682663"}, "86": {"model_id": "2024-06-01_16.36.55~7CYPIK", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.36.55~7CYPIK", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 5.736886030309187, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:46:05.801726"}, "87": {"model_id": "2024-06-01_16.37.11~4S7yjP", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.37.11~4S7yjP", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 13.141882102723162, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:46:19.068117"}, "88": {"model_id": "2024-06-01_16.44.55~noEERO", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.44.55~noEERO", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 11.414168740253169, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:53:57.912175"}, "89": {"model_id": "2024-06-01_16.46.05~0TuAH9", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.46.05~0TuAH9", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 10.38081307763491, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:55:09.479615"}, "90": {"model_id": "2024-06-01_16.46.19~rkVG0Y", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.46.19~rkVG0Y", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 9.333676737689807, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 16:55:23.242250"}, "91": {"model_id": "2024-06-01_16.53.58~18s50z", "parent_model_id": "2024-06-01_16.35.45~6uDZj0", "model_info": {"policy_id": "2024-06-01_16.53.58~18s50z", "parent_policy_id": "2024-06-01_16.35.45~6uDZj0", "score": 15.571406768441044, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 150}, "last_update_time": "2024-06-01 17:02:51.834476"}, "92": {"model_id": "2024-06-01_16.55.09~uqLlnU", "parent_model_id": "2024-06-01_16.35.45~6uDZj0", "model_info": {"policy_id": "2024-06-01_16.55.09~uqLlnU", "parent_policy_id": "2024-06-01_16.35.45~6uDZj0", "score": 8.21708448551933, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 150}, "last_update_time": "2024-06-01 17:04:03.873199"}, "93": {"model_id": "2024-06-01_16.55.23~9d5ECT", "parent_model_id": "2024-06-01_16.17.52~G4Y5Z5", "model_info": {"policy_id": "2024-06-01_16.55.23~9d5ECT", "parent_policy_id": "2024-06-01_16.17.52~G4Y5Z5", "score": 7.539391252707847, "steps_trained": 1300000, "env_steps_trained": 24000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-01 17:04:15.268071"}, "94": {"model_id": "2024-06-01_17.18.21~Pv6Ku5", "parent_model_id": "2024-06-01_16.01.23~xiZEvQ", "model_info": {"policy_id": "2024-06-01_17.18.21~Pv6Ku5", "parent_policy_id": "2024-06-01_16.01.23~xiZEvQ", "score": 7.65123657761154, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 17:27:01.780046"}, "95": {"model_id": "2024-06-01_17.18.44~KrNKYs", "parent_model_id": "2024-06-01_02.37.48~kiyN8D", "model_info": {"policy_id": "2024-06-01_17.18.44~KrNKYs", "parent_policy_id": "2024-06-01_02.37.48~kiyN8D", "score": 5.946321523653148, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 70}, "last_update_time": "2024-06-01 17:27:46.178923"}, "96": {"model_id": "2024-06-01_17.19.04~Xeds4n", "parent_model_id": "2024-06-01_16.53.58~18s50z", "model_info": {"policy_id": "2024-06-01_17.19.04~Xeds4n", "parent_policy_id": "2024-06-01_16.53.58~18s50z", "score": 7.264786883280802, "steps_trained": 1400000, "env_steps_trained": 25600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 160}, "last_update_time": "2024-06-01 17:28:15.377745"}, "97": {"model_id": "2024-06-01_17.27.01~56eaaZ", "parent_model_id": "2024-05-28_23.41.43~p5yas3", "model_info": {"policy_id": "2024-06-01_17.27.01~56eaaZ", "parent_policy_id": "2024-05-28_23.41.43~p5yas3", "score": 1.9663818732959983, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 10}, "last_update_time": "2024-06-01 17:36:21.666283"}, "98": {"model_id": "2024-06-01_17.27.46~ItCIwL", "parent_model_id": "2024-06-01_02.19.24~pnNiTk", "model_info": {"policy_id": "2024-06-01_17.27.46~ItCIwL", "parent_policy_id": "2024-06-01_02.19.24~pnNiTk", "score": 4.138158955378861, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 17:37:03.965038"}, "99": {"model_id": "2024-06-01_17.28.15~Lcjfcf", "parent_model_id": "2024-06-01_15.52.21~67CTkl", "model_info": {"policy_id": "2024-06-01_17.28.15~Lcjfcf", "parent_policy_id": "2024-06-01_15.52.21~67CTkl", "score": 8.295729331383185, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 17:37:31.852537"}, "100": {"model_id": "2024-06-01_17.36.21~jueliu", "parent_model_id": "2024-06-01_01.41.08~17KoZu", "model_info": {"policy_id": "2024-06-01_17.36.21~jueliu", "parent_policy_id": "2024-06-01_01.41.08~17KoZu", "score": 2.394554831149896, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 17:45:47.706376"}, "101": {"model_id": "2024-06-01_17.37.04~lzb8Tk", "parent_model_id": "2024-06-01_01.51.24~s8uzjj", "model_info": {"policy_id": "2024-06-01_17.37.04~lzb8Tk", "parent_policy_id": "2024-06-01_01.51.24~s8uzjj", "score": 4.103815594384363, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 17:46:31.205092"}, "102": {"model_id": "2024-06-01_17.37.32~WDgqau", "parent_model_id": "2024-06-01_16.46.05~0TuAH9", "model_info": {"policy_id": "2024-06-01_17.37.32~WDgqau", "parent_policy_id": "2024-06-01_16.46.05~0TuAH9", "score": 11.402751949641322, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 150}, "last_update_time": "2024-06-01 17:46:58.560333"}, "103": {"model_id": "2024-06-01_17.45.47~FDmjnN", "parent_model_id": "2024-06-01_03.05.44~VSxpgs", "model_info": {"policy_id": "2024-06-01_17.45.47~FDmjnN", "parent_policy_id": "2024-06-01_03.05.44~VSxpgs", "score": 6.0429211914385075, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 17:55:03.301938"}, "104": {"model_id": "2024-06-01_17.46.31~ilfDbs", "parent_model_id": "2024-06-01_02.00.13~Ya89fb", "model_info": {"policy_id": "2024-06-01_17.46.31~ilfDbs", "parent_policy_id": "2024-06-01_02.00.13~Ya89fb", "score": 3.57341706602128, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 50}, "last_update_time": "2024-06-01 17:55:48.570379"}, "105": {"model_id": "2024-06-01_17.46.58~RYg975", "parent_model_id": "2024-06-01_02.57.37~0VZDxc", "model_info": {"policy_id": "2024-06-01_17.46.58~RYg975", "parent_policy_id": "2024-06-01_02.57.37~0VZDxc", "score": 2.822015758860992, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 17:56:06.668533"}, "106": {"model_id": "2024-06-01_17.58.46~1xG8Ad", "parent_model_id": "2024-06-01_16.01.23~xiZEvQ", "model_info": {"policy_id": "2024-06-01_17.58.46~1xG8Ad", "parent_policy_id": "2024-06-01_16.01.23~xiZEvQ", "score": 8.400764862319317, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 18:07:28.857050"}, "107": {"model_id": "2024-06-01_17.59.10~d3Vky0", "parent_model_id": "2024-06-01_15.34.31~mO9siU", "model_info": {"policy_id": "2024-06-01_17.59.10~d3Vky0", "parent_policy_id": "2024-06-01_15.34.31~mO9siU", "score": 7.908297239023764, "steps_trained": 1200000, "env_steps_trained": 22400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 18:08:12.991684"}, "108": {"model_id": "2024-06-01_17.59.30~yt6oHs", "parent_model_id": "2024-06-01_16.01.23~xiZEvQ", "model_info": {"policy_id": "2024-06-01_17.59.30~yt6oHs", "parent_policy_id": "2024-06-01_16.01.23~xiZEvQ", "score": 8.713544178978761, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 18:08:39.722783"}, "109": {"model_id": "2024-06-01_18.12.27~hok4fT", "parent_model_id": "2024-06-01_15.06.14~1NyIvo", "model_info": {"policy_id": "2024-06-01_18.12.27~hok4fT", "parent_policy_id": "2024-06-01_15.06.14~1NyIvo", "score": 10.390817289473842, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 90}, "last_update_time": "2024-06-01 18:30:06.111041"}, "110": {"model_id": "2024-06-01_18.12.50~XFh5RF", "parent_model_id": "2024-06-01_16.10.14~ZZAb6N", "model_info": {"policy_id": "2024-06-01_18.12.50~XFh5RF", "parent_policy_id": "2024-06-01_16.10.14~ZZAb6N", "score": 20.431178689379088, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 150}, "last_update_time": "2024-06-01 18:30:48.413919"}, "111": {"model_id": "2024-06-01_18.13.10~bZtK0d", "parent_model_id": "2024-06-01_03.06.48~qjrQ5V", "model_info": {"policy_id": "2024-06-01_18.13.10~bZtK0d", "parent_policy_id": "2024-06-01_03.06.48~qjrQ5V", "score": 4.454392201038939, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 18:31:22.627007"}, "112": {"model_id": "2024-06-01_18.30.06~NuoFRQ", "parent_model_id": "2024-06-01_15.34.06~ZkTCox", "model_info": {"policy_id": "2024-06-01_18.30.06~NuoFRQ", "parent_policy_id": "2024-06-01_15.34.06~ZkTCox", "score": 6.83463074688607, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 130}, "last_update_time": "2024-06-01 18:47:51.986389"}, "113": {"model_id": "2024-06-01_18.30.48~LksojA", "parent_model_id": "2024-06-01_17.45.47~FDmjnN", "model_info": {"policy_id": "2024-06-01_18.30.48~LksojA", "parent_policy_id": "2024-06-01_17.45.47~FDmjnN", "score": 9.261345657474264, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 18:48:32.744982"}, "114": {"model_id": "2024-06-01_18.31.22~mmJK6O", "parent_model_id": "2024-06-01_18.12.50~XFh5RF", "model_info": {"policy_id": "2024-06-01_18.31.22~mmJK6O", "parent_policy_id": "2024-06-01_18.12.50~XFh5RF", "score": 13.83657713632001, "steps_trained": 1450000, "env_steps_trained": 26400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 170}, "last_update_time": "2024-06-01 18:49:08.272679"}, "115": {"model_id": "2024-06-01_18.47.52~KUGtmg", "parent_model_id": "2024-06-01_18.12.27~hok4fT", "model_info": {"policy_id": "2024-06-01_18.47.52~KUGtmg", "parent_policy_id": "2024-06-01_18.12.27~hok4fT", "score": 10.675338653056546, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 110}, "last_update_time": "2024-06-01 19:05:44.954570"}, "116": {"model_id": "2024-06-01_18.48.32~5YG6VS", "parent_model_id": "2024-06-01_18.12.50~XFh5RF", "model_info": {"policy_id": "2024-06-01_18.48.32~5YG6VS", "parent_policy_id": "2024-06-01_18.12.50~XFh5RF", "score": 5.537109012694352, "steps_trained": 1450000, "env_steps_trained": 26400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 170}, "last_update_time": "2024-06-01 19:06:18.929471"}, "117": {"model_id": "2024-06-01_18.49.08~1bGV0M", "parent_model_id": "2024-06-01_16.10.08~82CFFx", "model_info": {"policy_id": "2024-06-01_18.49.08~1bGV0M", "parent_policy_id": "2024-06-01_16.10.08~82CFFx", "score": 7.355527849561435, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 150}, "last_update_time": "2024-06-01 19:06:51.173807"}}}
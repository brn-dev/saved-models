{"_default": {"1": {"model_id": "2024-05-28_23.10.15~6QVFyI", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.10.15~6QVFyI", "parent_policy_id": null, "score": 0.02756274780800832, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.426600"}, "2": {"model_id": "2024-05-28_23.17.44~QlbUFa", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.17.44~QlbUFa", "parent_policy_id": null, "score": 0.03390417024646837, "steps_trained": 400000, "env_steps_trained": 9600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.539628"}, "3": {"model_id": "2024-05-28_23.18.28~rlRteB", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.18.28~rlRteB", "parent_policy_id": null, "score": 0.03419302204001851, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.608643"}, "4": {"model_id": "2024-05-28_23.25.50~AZeaFt", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.25.50~AZeaFt", "parent_policy_id": null, "score": 0.03560724578418207, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.686665"}, "5": {"model_id": "2024-05-28_23.33.35~CUWu2J", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.33.35~CUWu2J", "parent_policy_id": null, "score": 0.035249084915019886, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.812693"}, "6": {"model_id": "2024-05-28_23.41.43~p5yas3", "parent_model_id": null, "model_info": {"policy_id": "2024-05-28_23.41.43~p5yas3", "parent_policy_id": null, "score": 0.03, "steps_trained": 450000, "env_steps_trained": 10400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 0}, "last_update_time": "2024-06-01 19:31:04.961726"}, "7": {"model_id": "2024-06-01_19.39.19~4C7k9k", "parent_model_id": "2024-05-28_23.41.43~p5yas3", "model_info": {"policy_id": "2024-06-01_19.39.19~4C7k9k", "parent_policy_id": "2024-05-28_23.41.43~p5yas3", "score": 2.6993859467463714, "steps_trained": 550000, "env_steps_trained": 12000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 19:57:30.133698"}, "8": {"model_id": "2024-06-01_19.39.43~4mmb9m", "parent_model_id": "2024-05-28_23.25.50~AZeaFt", "model_info": {"policy_id": "2024-06-01_19.39.43~4mmb9m", "parent_policy_id": "2024-05-28_23.25.50~AZeaFt", "score": 2.890849776441346, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 19:58:13.659401"}, "9": {"model_id": "2024-06-01_19.40.03~UVdL1f", "parent_model_id": "2024-05-28_23.17.44~QlbUFa", "model_info": {"policy_id": "2024-06-01_19.40.03~UVdL1f", "parent_policy_id": "2024-05-28_23.17.44~QlbUFa", "score": 2.644076203757136, "steps_trained": 500000, "env_steps_trained": 11200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 20}, "last_update_time": "2024-06-01 19:58:42.108269"}, "10": {"model_id": "2024-06-01_19.57.30~gri35q", "parent_model_id": "2024-06-01_19.39.19~4C7k9k", "model_info": {"policy_id": "2024-06-01_19.57.30~gri35q", "parent_policy_id": "2024-06-01_19.39.19~4C7k9k", "score": 3.3988304026682443, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 20:15:54.981929"}, "11": {"model_id": "2024-06-01_19.58.13~FWqih9", "parent_model_id": "2024-06-01_19.39.19~4C7k9k", "model_info": {"policy_id": "2024-06-01_19.58.13~FWqih9", "parent_policy_id": "2024-06-01_19.39.19~4C7k9k", "score": 3.943218037788337, "steps_trained": 650000, "env_steps_trained": 13600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 20:16:52.065443"}, "12": {"model_id": "2024-06-01_19.58.42~jVf9Gw", "parent_model_id": "2024-06-01_19.40.03~UVdL1f", "model_info": {"policy_id": "2024-06-01_19.58.42~jVf9Gw", "parent_policy_id": "2024-06-01_19.40.03~UVdL1f", "score": 3.722397870464235, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 20:17:01.948940"}, "13": {"model_id": "2024-06-01_20.15.55~0R7M9r", "parent_model_id": "2024-06-01_19.40.03~UVdL1f", "model_info": {"policy_id": "2024-06-01_20.15.55~0R7M9r", "parent_policy_id": "2024-06-01_19.40.03~UVdL1f", "score": 2.9465388340552563, "steps_trained": 600000, "env_steps_trained": 12800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 40}, "last_update_time": "2024-06-01 20:34:04.593268"}, "14": {"model_id": "2024-06-01_20.16.52~3N9VrP", "parent_model_id": "2024-06-01_19.58.13~FWqih9", "model_info": {"policy_id": "2024-06-01_20.16.52~3N9VrP", "parent_policy_id": "2024-06-01_19.58.13~FWqih9", "score": 6.1246291110354765, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 20:35:15.093323"}, "15": {"model_id": "2024-06-01_20.17.02~3QKG6R", "parent_model_id": "2024-06-01_19.58.13~FWqih9", "model_info": {"policy_id": "2024-06-01_20.17.02~3QKG6R", "parent_policy_id": "2024-06-01_19.58.13~FWqih9", "score": 10.32193010595888, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 20:35:19.906336"}, "16": {"model_id": "2024-06-01_20.34.04~F7M86q", "parent_model_id": "2024-06-01_19.58.13~FWqih9", "model_info": {"policy_id": "2024-06-01_20.34.04~F7M86q", "parent_policy_id": "2024-06-01_19.58.13~FWqih9", "score": 4.906816072729688, "steps_trained": 750000, "env_steps_trained": 15200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 20:52:05.887110"}, "17": {"model_id": "2024-06-01_20.35.20~uh9LoV", "parent_model_id": "2024-06-01_19.58.42~jVf9Gw", "model_info": {"policy_id": "2024-06-01_20.35.20~uh9LoV", "parent_policy_id": "2024-06-01_19.58.42~jVf9Gw", "score": 4.261315263923412, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 20:53:22.805788"}, "19": {"model_id": "2024-06-01_20.52.06~lV5Ere", "parent_model_id": "2024-06-01_20.17.02~3QKG6R", "model_info": {"policy_id": "2024-06-01_20.52.06~lV5Ere", "parent_policy_id": "2024-06-01_20.17.02~3QKG6R", "score": 5.0155024839590805, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 21:10:14.475118"}, "20": {"model_id": "2024-06-01_20.53.22~4sBbxL", "parent_model_id": "2024-06-01_19.58.42~jVf9Gw", "model_info": {"policy_id": "2024-06-01_20.53.22~4sBbxL", "parent_policy_id": "2024-06-01_19.58.42~jVf9Gw", "score": 3.924042537579716, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 21:11:20.850354"}, "22": {"model_id": "2024-06-01_21.10.14~yLzeXh", "parent_model_id": "2024-06-01_20.16.52~3N9VrP", "model_info": {"policy_id": "2024-06-01_21.10.14~yLzeXh", "parent_policy_id": "2024-06-01_20.16.52~3N9VrP", "score": 6.040213471569497, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 21:28:39.280464"}, "23": {"model_id": "2024-06-01_21.11.21~26fcyT", "parent_model_id": "2024-06-01_20.17.02~3QKG6R", "model_info": {"policy_id": "2024-06-01_21.11.21~26fcyT", "parent_policy_id": "2024-06-01_20.17.02~3QKG6R", "score": 7.090531072549422, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 21:29:38.197566"}, "24": {"model_id": "2024-06-01_21.12.54~QyW0AE", "parent_model_id": "2024-06-01_20.53.22~4sBbxL", "model_info": {"policy_id": "2024-06-01_21.12.54~QyW0AE", "parent_policy_id": "2024-06-01_20.53.22~4sBbxL", "score": 4.3677596854021505, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 21:31:28.201505"}, "25": {"model_id": "2024-06-01_21.28.39~bUpgdN", "parent_model_id": "2024-06-01_20.15.55~0R7M9r", "model_info": {"policy_id": "2024-06-01_21.28.39~bUpgdN", "parent_policy_id": "2024-06-01_20.15.55~0R7M9r", "score": 3.5701532101000364, "steps_trained": 700000, "env_steps_trained": 14400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 60}, "last_update_time": "2024-06-01 21:47:25.794310"}, "26": {"model_id": "2024-06-01_21.29.38~gBNxNR", "parent_model_id": "2024-06-01_21.10.14~yLzeXh", "model_info": {"policy_id": "2024-06-01_21.29.38~gBNxNR", "parent_policy_id": "2024-06-01_21.10.14~yLzeXh", "score": 5.727920136859604, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 21:48:15.279949"}, "27": {"model_id": "2024-06-01_21.31.28~wfwOAa", "parent_model_id": "2024-06-01_20.35.20~uh9LoV", "model_info": {"policy_id": "2024-06-01_21.31.28~wfwOAa", "parent_policy_id": "2024-06-01_20.35.20~uh9LoV", "score": 6.243293008270906, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 21:50:09.326818"}, "28": {"model_id": "2024-06-01_21.47.25~Evu03T", "parent_model_id": "2024-06-01_20.34.04~F7M86q", "model_info": {"policy_id": "2024-06-01_21.47.25~Evu03T", "parent_policy_id": "2024-06-01_20.34.04~F7M86q", "score": 4.8214919482206255, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 22:05:42.989361"}, "29": {"model_id": "2024-06-01_21.48.15~CaqptX", "parent_model_id": "2024-06-01_21.29.38~gBNxNR", "model_info": {"policy_id": "2024-06-01_21.48.15~CaqptX", "parent_policy_id": "2024-06-01_21.29.38~gBNxNR", "score": 11.291297520588731, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-01 22:06:05.866406"}, "30": {"model_id": "2024-06-01_21.50.09~tEPEPy", "parent_model_id": "2024-06-01_20.17.02~3QKG6R", "model_info": {"policy_id": "2024-06-01_21.50.09~tEPEPy", "parent_policy_id": "2024-06-01_20.17.02~3QKG6R", "score": 8.851769155343483, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-01 22:08:19.394191"}, "31": {"model_id": "2024-06-01_22.05.43~T8uh1W", "parent_model_id": "2024-06-01_21.10.14~yLzeXh", "model_info": {"policy_id": "2024-06-01_22.05.43~T8uh1W", "parent_policy_id": "2024-06-01_21.10.14~yLzeXh", "score": 9.917796212649886, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 22:23:54.477534"}, "33": {"model_id": "2024-06-01_22.08.19~IP1JWC", "parent_model_id": "2024-06-01_20.52.06~lV5Ere", "model_info": {"policy_id": "2024-06-01_22.08.19~IP1JWC", "parent_policy_id": "2024-06-01_20.52.06~lV5Ere", "score": 4.99252209339072, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-01 22:26:44.358958"}, "34": {"model_id": "2024-06-02_01.18.19~AVovi0", "parent_model_id": "2024-06-01_21.48.15~CaqptX", "model_info": {"policy_id": "2024-06-02_01.18.19~AVovi0", "parent_policy_id": "2024-06-01_21.48.15~CaqptX", "score": 8.919460736449416, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-02 01:36:31.743933"}, "35": {"model_id": "2024-06-02_01.19.02~nJKFOM", "parent_model_id": "2024-06-01_21.50.09~tEPEPy", "model_info": {"policy_id": "2024-06-02_01.19.02~nJKFOM", "parent_policy_id": "2024-06-01_21.50.09~tEPEPy", "score": 10.990597858435148, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-02 01:37:17.774196"}, "36": {"model_id": "2024-06-02_01.18.42~3TZ4pt", "parent_model_id": "2024-06-01_20.35.20~uh9LoV", "model_info": {"policy_id": "2024-06-02_01.18.42~3TZ4pt", "parent_policy_id": "2024-06-01_20.35.20~uh9LoV", "score": 7.668760417210817, "steps_trained": 800000, "env_steps_trained": 16000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-02 01:37:41.625898"}, "37": {"model_id": "2024-06-02_01.36.31~ZeM5fH", "parent_model_id": "2024-06-01_20.17.02~3QKG6R", "model_info": {"policy_id": "2024-06-02_01.36.31~ZeM5fH", "parent_policy_id": "2024-06-01_20.17.02~3QKG6R", "score": 9.78074840726826, "steps_trained": 850000, "env_steps_trained": 16800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 80}, "last_update_time": "2024-06-02 01:55:11.173099"}, "38": {"model_id": "2024-06-02_01.37.41~WbOww7", "parent_model_id": "2024-06-02_01.19.02~nJKFOM", "model_info": {"policy_id": "2024-06-02_01.37.41~WbOww7", "parent_policy_id": "2024-06-02_01.19.02~nJKFOM", "score": 11.634738061137105, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 01:55:45.562973"}, "39": {"model_id": "2024-06-02_01.37.17~Lx43E2", "parent_model_id": "2024-06-01_21.50.09~tEPEPy", "model_info": {"policy_id": "2024-06-02_01.37.17~Lx43E2", "parent_policy_id": "2024-06-01_21.50.09~tEPEPy", "score": 11.943020145806843, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-02 01:56:02.013397"}, "40": {"model_id": "2024-06-02_01.55.11~ezssDB", "parent_model_id": "2024-06-02_01.18.19~AVovi0", "model_info": {"policy_id": "2024-06-02_01.55.11~ezssDB", "parent_policy_id": "2024-06-02_01.18.19~AVovi0", "score": 15.537819938625875, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 160}, "last_update_time": "2024-06-02 02:13:35.052718"}, "41": {"model_id": "2024-06-02_01.55.45~knfnhr", "parent_model_id": "2024-06-02_01.37.41~WbOww7", "model_info": {"policy_id": "2024-06-02_01.55.45~knfnhr", "parent_policy_id": "2024-06-02_01.37.41~WbOww7", "score": 13.300961864705513, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-02 02:14:03.280638"}, "42": {"model_id": "2024-06-02_01.56.02~Kf97Yk", "parent_model_id": "2024-06-01_21.11.21~26fcyT", "model_info": {"policy_id": "2024-06-02_01.56.02~Kf97Yk", "parent_policy_id": "2024-06-01_21.11.21~26fcyT", "score": 18.19454462533095, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-02 02:14:22.059348"}, "43": {"model_id": "2024-06-02_02.13.35~VExnND", "parent_model_id": "2024-06-01_22.05.43~T8uh1W", "model_info": {"policy_id": "2024-06-02_02.13.35~VExnND", "parent_policy_id": "2024-06-01_22.05.43~T8uh1W", "score": 12.782995293388009, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 02:32:06.162299"}, "44": {"model_id": "2024-06-02_02.14.03~HtJvYF", "parent_model_id": "2024-06-02_01.36.31~ZeM5fH", "model_info": {"policy_id": "2024-06-02_02.14.03~HtJvYF", "parent_policy_id": "2024-06-02_01.36.31~ZeM5fH", "score": 9.886104462334075, "steps_trained": 950000, "env_steps_trained": 18400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-02 02:32:38.993343"}, "45": {"model_id": "2024-06-02_02.14.22~kIHWAu", "parent_model_id": "2024-06-02_01.56.02~Kf97Yk", "model_info": {"policy_id": "2024-06-02_02.14.22~kIHWAu", "parent_policy_id": "2024-06-02_01.56.02~Kf97Yk", "score": 14.232518941623528, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 02:32:50.595740"}, "46": {"model_id": "2024-06-02_02.32.06~ezS4m0", "parent_model_id": "2024-06-02_01.56.02~Kf97Yk", "model_info": {"policy_id": "2024-06-02_02.32.06~ezS4m0", "parent_policy_id": "2024-06-02_01.56.02~Kf97Yk", "score": 11.994618452324787, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 02:50:20.757457"}, "47": {"model_id": "2024-06-02_02.32.39~owXfsg", "parent_model_id": "2024-06-02_01.56.02~Kf97Yk", "model_info": {"policy_id": "2024-06-02_02.32.39~owXfsg", "parent_policy_id": "2024-06-02_01.56.02~Kf97Yk", "score": 10.442879059585715, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 02:50:59.668634"}, "48": {"model_id": "2024-06-02_02.32.50~N4AleO", "parent_model_id": "2024-06-02_02.14.22~kIHWAu", "model_info": {"policy_id": "2024-06-02_02.32.50~N4AleO", "parent_policy_id": "2024-06-02_02.14.22~kIHWAu", "score": 9.768570651363127, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-02 02:51:28.902061"}, "49": {"model_id": "2024-06-02_02.50.20~LeZHIJ", "parent_model_id": "2024-06-02_01.56.02~Kf97Yk", "model_info": {"policy_id": "2024-06-02_02.50.20~LeZHIJ", "parent_policy_id": "2024-06-02_01.56.02~Kf97Yk", "score": 6.682679318575266, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 03:09:05.258743"}, "50": {"model_id": "2024-06-02_02.50.59~Q0CWPy", "parent_model_id": "2024-06-02_01.37.17~Lx43E2", "model_info": {"policy_id": "2024-06-02_02.50.59~Q0CWPy", "parent_policy_id": "2024-06-02_01.37.17~Lx43E2", "score": 8.574348667891783, "steps_trained": 1050000, "env_steps_trained": 20000000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 03:09:49.051846"}, "51": {"model_id": "2024-06-02_02.51.29~AbI24Z", "parent_model_id": "2024-06-02_01.55.11~ezssDB", "model_info": {"policy_id": "2024-06-02_02.51.29~AbI24Z", "parent_policy_id": "2024-06-02_01.55.11~ezssDB", "score": 22.336882505027205, "steps_trained": 1350000, "env_steps_trained": 24800000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 180}, "last_update_time": "2024-06-02 03:10:23.502746"}, "52": {"model_id": "2024-06-02_03.09.05~2Pd91V", "parent_model_id": "2024-06-02_01.18.42~3TZ4pt", "model_info": {"policy_id": "2024-06-02_03.09.05~2Pd91V", "parent_policy_id": "2024-06-02_01.18.42~3TZ4pt", "score": 12.251802733865777, "steps_trained": 900000, "env_steps_trained": 17600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 100}, "last_update_time": "2024-06-02 03:28:24.832517"}, "53": {"model_id": "2024-06-02_03.10.23~gva0vT", "parent_model_id": "2024-06-02_01.18.19~AVovi0", "model_info": {"policy_id": "2024-06-02_03.10.23~gva0vT", "parent_policy_id": "2024-06-02_01.18.19~AVovi0", "score": 9.491494919378585, "steps_trained": 1250000, "env_steps_trained": 23200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 160}, "last_update_time": "2024-06-02 03:29:07.126177"}, "54": {"model_id": "2024-06-02_03.09.49~aAhHrV", "parent_model_id": "2024-06-02_02.50.59~Q0CWPy", "model_info": {"policy_id": "2024-06-02_03.09.49~aAhHrV", "parent_policy_id": "2024-06-02_02.50.59~Q0CWPy", "score": 10.25061999553528, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-02 03:29:07.488259"}, "55": {"model_id": "2024-06-02_03.28.25~Wz7yHw", "parent_model_id": "2024-06-02_02.32.39~owXfsg", "model_info": {"policy_id": "2024-06-02_03.28.25~Wz7yHw", "parent_policy_id": "2024-06-02_02.32.39~owXfsg", "score": 8.043279948414426, "steps_trained": 1150000, "env_steps_trained": 21600000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 140}, "last_update_time": "2024-06-02 03:47:35.100448"}, "56": {"model_id": "2024-06-02_03.29.07~Qaw3Pc", "parent_model_id": "2024-06-02_03.09.05~2Pd91V", "model_info": {"policy_id": "2024-06-02_03.29.07~Qaw3Pc", "parent_policy_id": "2024-06-02_03.09.05~2Pd91V", "score": 12.354891824022504, "steps_trained": 1000000, "env_steps_trained": 19200000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 120}, "last_update_time": "2024-06-02 03:48:32.170497"}, "57": {"model_id": "2024-06-02_03.29.07~Oz0oTT", "parent_model_id": "2024-06-02_02.51.29~AbI24Z", "model_info": {"policy_id": "2024-06-02_03.29.07~Oz0oTT", "parent_policy_id": "2024-06-02_02.51.29~AbI24Z", "score": 12.632038610538277, "steps_trained": 1450000, "env_steps_trained": 26400000, "init_policy_source_code": "def init_policy():\n    import numpy as np\n    import torch\n    from torch import nn\n\n    from src.networks.core.net import Net\n    from src.networks.core.seq_net import SeqNet\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.networks.multihead_self_attention import MultiheadSelfAttention\n    \n    in_size = 8\n    action_size = 2\n    \n    actor_layers = 3\n    actor_features = 48\n    \n    critic_layers = 2\n    critic_features = 48\n\n    actor_hidden_activation_function = nn.ELU\n    critic_hidden_activation_function = nn.ELU\n    \n    actor_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n    critic_hidden_initialization = lambda module: orthogonal_initialization(module, gain=np.sqrt(2))\n\n    class A2CNetwork(nn.Module):\n\n        def __init__(self):\n            super().__init__()\n\n            self.actor_embedding = nn.Sequential(nn.Linear(in_size, actor_features), actor_hidden_activation_function())\n            self.actor = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        actor_hidden_activation_function(),\n                        actor_hidden_initialization(nn.Linear(in_features, out_features)),\n                        nn.Tanh() if is_last_layer else actor_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=actor_layers,\n                num_features=actor_features,\n            )\n\n            self.critic_embedding = nn.Sequential(nn.Linear(in_size, critic_features), critic_hidden_activation_function())\n            self.critic = SeqNet.from_layer_provider(\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n                    AdditiveSkipConnection(MultiheadSelfAttention(\n                        embed_dim=in_features,\n                        num_heads=4,\n                        batch_first=True,\n                    )),\n                    nn.LayerNorm(in_features),\n                    AdditiveSkipConnection(Net.sequential_net(\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                        critic_hidden_initialization(nn.Linear(in_features, out_features)),\n                        critic_hidden_activation_function(),\n                    )),\n                    nn.LayerNorm(in_features),\n                ),\n                num_layers=critic_layers,\n                num_features=critic_features,\n            )\n            self.critic_regressor = nn.Linear(critic_features, 1)\n\n        def forward(self, x: torch.Tensor):\n            *batch_shape, nr_actors, nr_features = x.shape\n            x = torch.flatten(x, end_dim=-3)\n            \n            actor_out: torch.Tensor = self.actor(self.actor_embedding(x))\n            critic_out: torch.Tensor = self.critic_regressor(self.critic(self.critic_embedding(x)).sum(dim=-2))\n            \n            actor_out = actor_out.unflatten(dim=0, sizes=batch_shape)\n            critic_out = critic_out.unflatten(dim=0, sizes=batch_shape)\n            \n            return actor_out, critic_out\n        \n    return ActorCriticPolicy(A2CNetwork(), SquashedDiagGaussianActionSelector(\n        latent_dim=actor_features,\n        action_dim=action_size,\n        std=0.15,\n        std_learnable=False,\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    ))\n", "wrap_env_source_code": "def wrap_env(env_):\n    return env_\n", "optimizations_done": 200}, "last_update_time": "2024-06-02 03:48:35.754943"}}}